<!DOCTYPE html>
<html>
  <head>
    <title>Data Integrity ECDSA Cryptosuites v1.0</title>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <!--
      === NOTA BENE ===
      For the three scripts below, if your spec resides on dev.w3 you can check them
      out in the same tree and use relative links so that they'll work offline,
     -->
    <script src="//www.w3.org/Tools/respec/respec-w3c" class="remove"></script>
    <script class="remove" src="https://w3c.github.io/vc-data-integrity/common.js"></script>

    <script type="text/javascript" class="remove">
      var respecConfig = {
        subtitle: "Achieving Data Integrity using ECDSA with NIST-compliant curves",
        // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
        group: "vc",
        specStatus: "WD",

        // the specification's short name, as in http://www.w3.org/TR/short-name/
        shortName: "vc-di-ecdsa",

        // if you wish the publication date to be other than today, set this
        //publishDate:  "2023-04-18",

        // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
        // and its maturity status
        // previousPublishDate:  "1977-03-15",
        // previousMaturity:  "WD",

        // if there a publicly available Editor's Draft, this is the link
        edDraftURI: "https://w3c.github.io/vc-di-ecdsa/",
        //latestVersion: "https://www.w3.org/community/reports/credentials/CG-FINAL-di-ecdsa-2019-20220724/",

        // if this is a LCWD, uncomment and set the end of its review period
        // lcEnd: "2009-08-05",

        // if you want to have extra CSS, append them to this list
        // it is recommended that the respec.css stylesheet be kept
        //extraCSS:             ["spec.css", "prettify.css"],

        // editors, add as many as you like
        // only "name" is required
        editors: [{
          name: "Manu Sporny",
          url: "https://www.linkedin.com/in/manusporny/",
          company: "Digital Bazaar",
          companyURL: "https://digitalbazaar.com/",
          w3cid: 41758
        }, {
          name: "Marty Reed",
          url: "https://www.linkedin.com/in/marty-reed-b5b2352/",
          company: "RANDA Solutions",
          companyURL: "https://www.randasolutions.com/",
          w3cid: 127611
        }, {
          name: "Greg Bernstein", url: "https://www.grotto-networking.com/",
          company: "Invited Expert", w3cid: 140479
        }, {
          name: "Sebastian Crane", url: "https://github.com/seabass-labrax",
          company: "Invited Expert", w3cid: 140132
        }],

        // authors, add as many as you like.
        // This is optional, uncomment if you have authors as well as editors.
        // only "name" is required. Same format as editors.

        authors: [{
          name: "Dave Longley", url: "https://digitalbazaar.com/",
          company: "Digital Bazaar", companyURL: "https://digitalbazaar.com/",
          w3cid: 48025
        }, {
          name: "Manu Sporny", url: "https://www.linkedin.com/in/manusporny/",
          company: "Digital Bazaar", companyURL: "https://digitalbazaar.com/",
          w3cid: 41758
        }],

        // extend the bibliography entries
        //localBiblio: webpayments.localBiblio,

        // name of the WG
        //wg:           "W3C Credentials Community Group",

        // URI of the public WG page
        //wgURI:        "https://www.w3.org/community/credentials/",

        // name (with the @w3c.org) of the public mailing to which comments are due
        //wgPublicList: "public-credentials",

        github: "https://github.com/w3c/vc-di-ecdsa/",

        otherLinks: [],

        // URI of the patent status for this WG, for Rec-track documents
        // !!!! IMPORTANT !!!!
        // This is important for Rec-track documents, do not copy a patent URI from a random
        // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
        // Team Contact.
        // wgPatentURI:  "",
        maxTocLevel: 4,
        /*preProcess: [ webpayments.preProcess ],
        alternateFormats: [ {uri: "diff-20111214.html", label: "diff to previous version"} ],
        */
        localBiblio: {
          MULTIBASE: {
            title: "Multibase",
            href: "https://datatracker.ietf.org/doc/html/draft-multiformats-multibase-01",
          },
          MULTICODEC: {
            title: "Multicodec",
            href: "https://github.com/multiformats/multicodec/",
          },
          SECG2: {
            title: "SEC 2: Recommended Elliptic Curve Domain Parameters",
            href: "http://www.secg.org/sec2-v2.pdf",
            date: "January 27, 2010",
            publisher: "Certicom Research"
          },
          "NIST-SP-800-186": {
            title: "Recommendations for Discrete Logarithm-based Cryptography: Elliptic Curve Domain Parameters",
            authors: ["Lily Chen", "Dustin Moody", "Karen Randall", "Andrew Regenscheid", "Angela Robinson"],
            date: "February 2023",
            publisher: "National Institute of Standards and Technology"
          },
          "NIST-SP-800-186": {
            title: "Recommendations for Discrete Logarithm-based Cryptography: Elliptic Curve Domain Parameters",
            authors: ["Lily Chen", "Dustin Moody", "Karen Randall", "Andrew Regenscheid", "Angela Robinson"],
            date: "February 2023",
            publisher: "National Institute of Standards and Technology"
          },
          "NIST-SP-800-57-Part-1": {
            title: "Recommendation for Key Management: Part 1 â€“ General",
            authors: ["Elaine Barker"],
            date: "May 2020",
            publisher: "National Institute of Standards and Technology",
            href: "https://doi.org/10.6028/NIST.SP.800-57pt1r5"
          }
        },
        lint: {"no-unused-dfns": false},
        postProcess: [restrictRefs],
        otherLinks: [{
          key: "Related Specifications",
          data: [{
            value: "The Verifiable Credentials Data Model v2.0",
            href: "https://www.w3.org/TR/vc-data-model-2.0/"
          }, {
            value: "Verifiable Credential Data Integrity v1.0",
            href: "https://www.w3.org/TR/vc-data-integrity/"
          }, {
            value: "The Edwards Digital Signature Algorithm Cryptosuites v1.0",
            href: "https://www.w3.org/TR/vc-di-eddsa/"
          }, {
            value: "The BBS Digital Signature Algorithm Cryptosuites v1.0",
            href: "https://www.w3.org/TR/vc-di-bbs/"
          }]
        }]
      };
    </script>
    <style>
code {
  color: rgb(199, 73, 0);
  font-weight: bold;
}
pre.nohighlight {
  overflow-x: auto;
  white-space: pre-wrap;
}
pre .highlight {
  font-weight: bold;
  color: green;
}
pre .comment {
  font-weight: bold;
  color: Gray;
}
.color-text {
  font-weight: bold;
  text-shadow: -1px 0 black, 0 1px black, 1px 0 black, 0 -1px black;
}
ol.algorithm {
  counter-reset: numsection;
  list-style-type: none;
}
ol.algorithm li {
  margin: 0.5em 0;
}
ol.algorithm li:before {
  font-weight: bold;
  counter-increment: numsection;
  content: counters(numsection, ".") ") ";
}
    </style>
  </head>
  <body>
    <section id="abstract">
      <p>
This specification describes a Data Integrity Cryptosuite for use when
generating a digital signature using the Elliptic Curve Digital Signature
Algorithm (ECDSA).
      </p>
    </section>

    <section id="sotd">
      <p>
This is an experimental specification and is undergoing regular revisions. It
is not fit for production deployment.
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
This specification defines a cryptographic suite for the purpose of creating,
and verifying proofs for ECDSA signatures in conformance with the
Data Integrity [[VC-DATA-INTEGRITY]] specification. ECDSA signatures are
specified in [[FIPS-186-5]] with elliptic curves P-256 and P-384 specified in
[[NIST-SP-800-186]]. [[FIPS-186-5]] includes the <em>deterministic</em> ECDSA
algorithm which is also specified in [[RFC6979]].
      </p>
      <p>
This specification uses either the RDF Dataset Canonicalization Algorithm
[[RDF-CANON]] or the JSON Canonicalization Scheme [[RFC8785]] to transform the
input document into its canonical form. It uses one of two mechanisms to digest
and sign: SHA-256 [[RFC6234]] as the message digest algorithm and ECDSA with
Curve P-256 as the signature algorithm, or SHA-384 [[RFC6234]] as the message
digest algorithm and ECDSA with Curve P-384 as the signature algorithm.
      </p>
      <p class="note">
The elliptic curves P-256 and P-384 of [[NIST-SP-800-186]] are referred to as
<em>secp256r1</em> and <em>secp384r1</em> respectively in [[SECG2]]. In
addition, this notation is sometimes used in ECDSA software libraries.
      </p>

      <section id="terminology">
        <h3>Terminology</h3>

        <div data-include="https://w3c.github.io/vc-data-integrity/terms.html"></div>

      </section>

      <section id="conformance">
        <p>
A <dfn>conforming proof</dfn> is any concrete expression of the data model
that complies with the normative statements in this specification. Specifically,
all relevant normative statements in Sections
<a href="#data-model"></a> and <a href="#algorithms"></a>
of this document MUST be enforced.
        </p>

        <p>
A <dfn class="lint-ignore">conforming processor</dfn> is any algorithm realized
as software and/or hardware that generates or consumes a
<a>conforming proof</a>. Conforming processors MUST produce errors when
non-conforming documents are consumed.
        </p>
        <p>
This document also contains examples that contain JSON and JSON-LD content. Some
of these examples contain characters that are invalid JSON, such as inline
comments (`//`) and the use of ellipsis (`...`) to denote
information that adds little value to the example. Implementers are cautioned to
remove this content if they desire to use the information as valid JSON or
JSON-LD.
        </p>
      </section>

    </section>

    <section>
      <h2>Data Model</h2>

      <p>
The following sections outline the data model that is used by this specification
to express verification methods, such as cryptographic public keys, and
data integrity proofs, such as digital signatures.
      </p>

      <section>
        <h3>Verification Methods</h3>

        <p>
These verification methods are used to verify Data Integrity Proofs
[[VC-DATA-INTEGRITY]] produced using Elliptic Curve cryptographic key material
that is compliant with [[FIPS-186-5]]. The encoding formats for these key types
are provided in this section. Lossless cryptographic key transformation
processes that result in equivalent cryptographic key material MAY be used
during the processing of digital signatures.
        </p>

        <section>
          <h4>Multikey</h4>

          <p>
The <a data-cite="VC-DATA-INTEGRITY#multikey">Multikey format</a>, as defined in
[[VC-DATA-INTEGRITY]], is used to express public keys for the cryptographic
suites defined in this specification.
          </p>

          <p>
The `publicKeyMultibase` property represents a Multibase-encoded Multikey
expression of a P-256 or P-384 public key. The encoding of a P-256 public key is
the two-byte prefix `0x8024` (the varint expression of `0x1200`) followed
by the 33-byte compressed public key data.
The 35-byte value is then encoded using base58-btc (`z`) as the prefix. The
encoding of a P-384 public key is the two-byte prefix `0x8124` (the varint
expression of `0x1201`) followed by the 49-byte compressed public key data.
The 51-byte value is then encoded using base58-btc (`z`) as the prefix. Any
other encodings MUST NOT be allowed.
          </p>

          <p class="advisement">
Developers are advised to not accidentally publish a representation of a private
key. Implementations of this specification will raise errors in the event of a
[[MULTICODEC]] value other than `0x1200` or `0x1201` being used in a
`publicKeyMultibase` value.
          </p>

          <pre class="example nohighlight"
            title="An P-256 public key encoded as a Multikey">
{
  "id": "https://example.com/issuer/123#key-0",
  "type": "Multikey",
  "controller": "https://example.com/issuer/123",
  "publicKeyMultibase": "zDnaerx9CtbPJ1q36T5Ln5wYt3MQYeGRG5ehnPAmxcf5mDZpv"
}
          </pre>

          <pre class="example nohighlight"
            title="An P-384 public key encoded as a Multikey">
{
  "id": "https://example.com/issuer/123#key-0",
  "type": "Multikey",
  "controller": "https://example.com/issuer/123",
  "publicKeyMultibase": "z82LkvCwHNreneWpsgPEbV3gu1C6NFJEBg4srfJ5gdxEsMGRJ
    Uz2sG9FE42shbn2xkZJh54"
}
          </pre>

          <pre class="example nohighlight" title="Two public keys (P-256 and P-384)
            encoded as Multikeys in a controller document">
{
  "@context": [
    "https://www.w3.org/ns/did/v1",
    "https://w3id.org/security/data-integrity/v1"
  ],
  "id": "did:example:123",
  "verificationMethod": [{
    "id": "https://example.com/issuer/123#key-1",
    "type": "Multikey",
    "controller": "https://example.com/issuer/123",
    "publicKeyMultibase": "zDnaerx9CtbPJ1q36T5Ln5wYt3MQYeGRG5ehnPAmxcf5mDZpv"
  }, {
    "id": "https://example.com/issuer/123#key-2",
    "type": "Multikey",
    "controller": "https://example.com/issuer/123",
    "publicKeyMultibase": "z82LkvCwHNreneWpsgPEbV3gu1C6NFJEBg4srfJ5gdxEsMGRJ
      Uz2sG9FE42shbn2xkZJh54"
  }],
  "authentication": [
    "did:example:123#key-1"
  ],
  "assertionMethod": [
    "did:example:123#key-2"
  ],
  "capabilityDelegation": [
    "did:example:123#key-2"
  ],
  "capabilityInvocation": [
    "did:example:123#key-2"
  ]
}
          </pre>
        </section>

      </section>

      <section>
        <h3>Proof Representations</h3>

        <p>
This suite relies on detached digital signatures represented using [[MULTIBASE]]
and [[MULTICODEC]].
        </p>

        <section>
          <h4>DataIntegrityProof</h4>

          <p>
The `verificationMethod` property of the proof MUST be a URL.
Dereferencing the `verificationMethod` MUST result in an object
containing a `type` property with the value set to
`Multikey`.
          </p>

          <p>
The `type` property of the proof MUST be `DataIntegrityProof`.
          </p>
          <p>
The `cryptosuite` property of the proof MUST be `ecdsa-rdfc-2019` or `ecdsa-jcs-2019`.
          </p>
          <p>
The `created` property of the proof MUST be an [[XMLSCHEMA11-2]]
formatted date string.
          </p>
          <p>
The `proofPurpose` property of the proof MUST be a string, and MUST
match the verification relationship expressed by the verification method
`controller`.
          </p>
          <p>
The `proofValue` property of the proof MUST be an ECDSA or deterministic ECDSA
signature produced according to [[FIPS-186-5]] using the curves and hashes as
specified in section <a href="#algorithms"></a>, encoded according to section 7
of [[RFC4754]] (sometimes referred to as the IEEE P1363 format), and serialized
according to [[MULTIBASE]] using the base58-btc base encoding.
          </p>

          <pre class="example nohighlight"
            title="An ECDSA P-256 digital signature expressed as a
              DataIntegrityProof">
{
  "@context": [
    {"title": "https://schema.org/title"},
    "https://w3id.org/security/data-integrity/v1"
  ],
  "title": "Hello world!",
  "proof": {
    "type": "DataIntegrityProof",
    "cryptosuite": "ecdsa-2019",
    "created": "2020-11-05T19:23:24Z",
    "verificationMethod": "https://example.com/issuer/123#key-2",
    "proofPurpose": "assertionMethod",
    "proofValue": "z4oey5q2M3XKaxup3tmzN4DRFTLVqpLMweBrSxMY2xHX5XTYVQeVbY8nQA
      VHMrXFkXJpmEcqdoDwLWxaqA3Q1geV6"
  }
}
          </pre>

        </section>
      </section>
    </section>

    <section>
      <h2>Algorithms</h2>

      <p>
The following section describes multiple Data Integrity cryptographic suites
that utilize the Elliptic Curve Digital Signature Algorithm (ECDSA) [[FIPS-186-5]].
      </p>

      <section>
        <h3>ecdsa-rdfc-2019</h3>

        <p>
The `ecdsa-rdfc-2019` cryptographic suite takes an input document, canonicalizes
the document using the Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]], and then cryptographically hashes and signs the output
resulting in the production of a data integrity proof. The algorithms in this
section also include the verification of such a data integrity proof.
        </p>

        <p class="advisement">
When the RDF Dataset Canonicalization Algorithm [[RDF-CANON]] is used,
implementations of that algorithm will detect
<a data-cite="RDF-CANON#dataset-poisoning">dataset poisoning</a>
by default, and abort processing upon detection.
        </p>

        <section>
          <h4>Add Proof (ecdsa-rdfc-2019)</h4>

          <p>
To generate a proof, the algorithm in
<a href="https://www.w3.org/TR/vc-data-integrity/#add-proof">
Section 4.1: Add Proof</a> in the Data Integrity
[[VC-DATA-INTEGRITY]] specification MUST be executed.
For that algorithm, the cryptographic suite specific
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-transformation-algorithm">
transformation algorithm</a> is defined in Section
<a href="#transformation-ecdsa-rdfc-2019"></a>, the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-hashing-algorithm">
hashing algorithm</a> is defined in Section <a href="#hashing-ecdsa-rdfc-2019"></a>,
and the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-proof-serialization-algorithm">
proof serialization algorithm</a> is defined in Section
<a href="#proof-serialization-ecdsa-rdfc-2019"></a>.
          </p>
        </section>

        <section>
          <h4>Verify Proof (ecdsa-rdfc-2019)</h4>

          <p>
To verify a proof, the algorithm in
<a href="https://www.w3.org/TR/vc-data-integrity/#verify-proof">
Section 4.2: Verify Proof</a> in the Data Integrity
[[VC-DATA-INTEGRITY]] specification MUST be executed.
For that algorithm, the cryptographic suite specific
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-transformation-algorithm">
transformation algorithm</a> is defined in Section
<a href="#transformation-ecdsa-rdfc-2019"></a>, the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-hashing-algorithm">
hashing algorithm</a> is defined in Section <a href="#hashing-ecdsa-rdfc-2019"></a>,
and the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-proof-serialization-algorithm">
proof verification algorithm</a> is defined in Section
<a href="#proof-verification-ecdsa-rdfc-2019"></a>.
          </p>
        </section>

        <section>
          <h4>Transformation (ecdsa-rdfc-2019)</h4>

          <p>
The following algorithm specifies how to transform an unsecured input document
into a transformed document that is ready to be provided as input to the
hashing algorithm in Section <a href="#hashing-ecdsa-rdfc-2019"></a>.
          </p>

          <p>
Required inputs to this algorithm are an
<a data-cite="vc-data-integrity#dfn-unsecured-data-document">
unsecured data document</a> (<var>unsecuredDocument</var>) and
transformation options (<var>options</var>). The
transformation options MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and a cryptosuite
identifier (<var>cryptosuite</var>). A <em>transformed data document</em> is
produced as output. Whenever this algorithm encodes strings, it MUST use UTF-8
encoding.
          </p>

          <ol class="algorithm">
            <li>
If <var>options</var>.<var>type</var> is not set to the string
`DataIntegrityProof` and <var>options</var>.<var>cryptosuite</var> is not
set to the string `ecdsa-rdfc-2019` then a `PROOF_TRANSFORMATION_ERROR` MUST be
raised.
            </li>
            <li>
Let <var>canonicalDocument</var> be the result of applying the
Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]] to the <var>unsecuredDocument</var>.
            </li>
            <li>
Set <var>output</var> to the value of <var>canonicalDocument</var>.
            </li>
            <li>
Return <var>canonicalDocument</var> as the <em>transformed data document</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>Hashing (ecdsa-rdfc-2019)</h4>

          <p>
The following algorithm specifies how to cryptographically hash a
<em>transformed data document</em> and <em>proof configuration</em>
into cryptographic hash data that is ready to be provided as input to the
algorithms in Section <a href="#proof-serialization-ecdsa-rdfc-2019"></a> or
Section <a href="#proof-verification-ecdsa-rdfc-2019"></a>. One must use the hash
algorithm appropriate in security level to the curve used, i.e., for curve
P-256 one uses SHA-256 and for curve P-384 one uses SHA-384.
          </p>

          <p>
The required inputs to this algorithm are a <em>transformed data document</em>
(<var>transformedDocument</var>) and <em>canonical proof configuration</em>
(<var>canonicalProofConfig</var>). A single <em>hash data</em> value represented as
series of bytes is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>transformedDocumentHash</var> be the result of applying the
SHA-256 (SHA-2 with 256-bit output) or SHA-384 (SHA-2 with 384-bit output)
cryptographic hashing algorithm [[RFC6234]] to the
respective curve P-256 or curve P-384 <var>transformedDocument</var>.
Respective <var>transformedDocumentHash</var> will be exactly 32 or 48 bytes
in size.
            </li>
            <li>
Let <var>proofConfigHash</var> be the result of applying the
SHA-256 (SHA-2 with 256-bit output) or SHA-384 (SHA-2 with 384-bit output)
cryptographic hashing algorithm [[RFC6234]] to the respective curve P-256 or curve P-384
<var>canonicalProofConfig</var>. Respective <var>proofConfigHash</var>
will be exactly 32 or 48 bytes in size.
            </li>
            <li>
Let <var>hashData</var> be the result of joining <var>proofConfigHash</var> (the
first hash) with <var>transformedDocumentHash</var> (the second hash).
            </li>
            <li>
Return <var>hashData</var> as the <em>hash data</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Proof Configuration (ecdsa-rdfc-2019)</h4>

          <p>
The following algorithm specifies how to generate a
<em>proof configuration</em> from a set of <em>proof options</em>
that is used as input to the <a href="#hashing-ecdsa-rdfc-2019">proof hashing algorithm</a>.
          </p>

          <p>
The required inputs to this algorithm are <em>proof options</em>
(<var>options</var>). The <em>proof options</em> MUST contain a type identifier
for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MUST contain a cryptosuite
identifier (<var>cryptosuite</var>). A <em>proof configuration</em>
object is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>proofConfig</var> be an empty object.
            </li>
            <li>
Set <var>proofConfig</var>.<var>type</var> to
<var>options</var>.<var>type</var>.
            </li>
            <li>
If <var>options</var>.<var>cryptosuite</var> is set, set
<var>proofConfig</var>.<var>cryptosuite</var> to its value.
            </li>
            <li>
If <var>options</var>.<var>type</var> is not set to `DataIntegrityProof` and
<var>proofConfig</var>.<var>cryptosuite</var> is not set to `ecdsa-rdfc-2019`, an
`INVALID_PROOF_CONFIGURATION` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>created</var> to
<var>options</var>.<var>created</var>. If the value is not a valid
[[XMLSCHEMA11-2]] datetime, an `INVALID_PROOF_DATETIME` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>verificationMethod</var> to
<var>options</var>.<var>verificationMethod</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>proofPurpose</var> to
<var>options</var>.<var>proofPurpose</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>@context</var> to
<var>unsecuredDocument</var>.<var>@context</var>.
            </li>
            <li>
Let <var>canonicalProofConfig</var> be the result of applying the
Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]] to the <var>proofConfig</var>.
            </li>
            <li>
Return <var>canonicalProofConfig</var>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Proof Serialization (ecdsa-rdfc-2019)</h4>

          <p>
The following algorithm specifies how to serialize a digital signature from
a set of cryptographic hash data. This
algorithm is designed to be used in conjunction with the algorithms defined
in the Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Algorithms</a>. Required inputs are
cryptographic hash data (<var>hashData</var>) and
<em>proof options</em> (<var>options</var>). The
<em>proof options</em> MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MAY contain a cryptosuite
identifier (<var>cryptosuite</var>). A single <em>digital proof</em> value
represented as series of bytes is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>privateKeyBytes</var> be the result of retrieving the
private key bytes associated with the
<var>options</var>.<var>verificationMethod</var> value as described in the
Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Retrieving Cryptographic Material</a>.
            </li>
            <li>
Let <var>proofBytes</var> be the result of applying the Elliptic Curve Digital
Signature Algorithm (ECDSA) [[FIPS-186-5]], with <var>hashData</var> as the data
to be signed using the private key specified by <var>privateKeyBytes</var>.
<var>proofBytes</var> will be exactly 64 bytes in size for a P-256 key, and
96 bytes in size for a P-384 key.
            </li>
            <li>
Return <var>proofBytes</var> as the <em>digital proof</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Proof Verification (ecdsa-rdfc-2019)</h4>

          <p>
The following algorithm specifies how to verify a digital signature from
a set of cryptographic hash data. This
algorithm is designed to be used in conjunction with the algorithms defined
in the Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Algorithms</a>. Required inputs are
cryptographic hash data (<var>hashData</var>),
a digital signature (<var>proofBytes</var>) and
proof options (<var>options</var>). A <em>verification result</em>
represented as a boolean value is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>publicKeyBytes</var> be the result of retrieving the
public key bytes associated with the
<var>options</var>.<var>verificationMethod</var> value as described in the
Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Retrieving Cryptographic Material</a>.
            </li>
            <li>
Let <var>verificationResult</var> be the result of applying the verification
algorithm Elliptic Curve Digital Signature Algorithm (ECDSA) [[FIPS-186-5]],
with <var>hashData</var> as the data to be verified against the
<var>proofBytes</var> using the public key specified by
<var>publicKeyBytes</var>.
            </li>
            <li>
Return <var>verificationResult</var> as the <em>verification result</em>.
            </li>
          </ol>

        </section>
      </section>
      <section>
        <h3>ecdsa-jcs-2019</h3>

        <p>
The `ecdsa-jcs-2019` cryptographic suite takes an input document, canonicalizes
the document using the JSON Canonicalization Scheme [[RFC8785]], and then
cryptographically hashes and signs the output
resulting in the production of a data integrity proof. The algorithms in this
section also include the verification of such a data integrity proof.
        </p>

        <section>
          <h4>Add Proof (ecdsa-jcs-2019)</h4>

          <p>
To generate a proof, the algorithm in
<a href="https://www.w3.org/TR/vc-data-integrity/#add-proof">
Section 4.1: Add Proof</a> of the Data Integrity
[[VC-DATA-INTEGRITY]] specification MUST be executed.
For that algorithm, the cryptographic suite-specific
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-transformation-algorithm">
transformation algorithm</a> is defined in Section
<a href="#transformation-ecdsa-jcs-2019"></a>, the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-hashing-algorithm">
hashing algorithm</a> is defined in Section <a href="#hashing-ecdsa-jcs-2019"></a>,
and the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-proof-serialization-algorithm">
proof serialization algorithm</a> is defined in Section
<a href="#proof-serialization-ecdsa-jcs-2019"></a>.
          </p>
        </section>

        <section>
          <h4>Verify Proof (ecdsa-jcs-2019)</h4>

          <p>
To verify a proof, the algorithm in
<a href="https://www.w3.org/TR/vc-data-integrity/#verify-proof">
Section 4.2: Verify Proof</a> of the Data Integrity
[[VC-DATA-INTEGRITY]] specification MUST be executed.
For that algorithm, the cryptographic suite-specific
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-transformation-algorithm">
transformation algorithm</a> is defined in Section
<a href="#transformation-ecdsa-jcs-2019"></a>, the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-hashing-algorithm">
hashing algorithm</a> is defined in Section <a href="#hashing-ecdsa-jcs-2019"></a>,
and the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-proof-serialization-algorithm">
proof verification algorithm</a> is defined in Section
<a href="#proof-verification-ecdsa-jcs-2019"></a>.
          </p>
        </section>

        <section>
          <h4>Transformation (ecdsa-jcs-2019)</h4>

          <p>
The following algorithm specifies how to transform an unsecured input document
into a transformed document that is ready to be provided as input to the
hashing algorithm in Section <a href="#hashing-ecdsa-jcs-2019"></a>.
          </p>

          <p>
Required inputs to this algorithm are an
<a data-cite="vc-data-integrity#dfn-unsecured-data-document">
unsecured data document</a> (<var>unsecuredDocument</var>) and
transformation options (<var>options</var>). The
transformation options MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and a cryptosuite
identifier (<var>cryptosuite</var>). A <em>transformed data document</em> is
produced as output. Whenever this algorithm encodes strings, it MUST use UTF-8
encoding.
          </p>

          <ol class="algorithm">
            <li>
If <var>options</var>.<var>type</var> is not set to the string
`DataIntegrityProof` and <var>options</var>.<var>cryptosuite</var> is not
set to the string `ecdsa-jcs-2019`, then a `PROOF_TRANSFORMATION_ERROR` MUST be
raised.
            </li>
            <li>
Let <var>canonicalDocument</var> be the result of applying the
JSON Canonicalization Scheme [[RFC8785]] to the <var>unsecuredDocument</var>.
            </li>
            <li>
Set <var>output</var> to the value of <var>canonicalDocument</var>.
            </li>
            <li>
Return <var>canonicalDocument</var> as the <em>transformed data document</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>Hashing (ecdsa-jcs-2019)</h4>

          <p>
The following algorithm specifies how to cryptographically hash a
<em>transformed data document</em> and <em>proof configuration</em>
into cryptographic hash data that is ready to be provided as input to the
algorithms in Section <a href="#proof-serialization-ecdsa-jcs-2019"></a> or
Section <a href="#proof-verification-ecdsa-jcs-2019"></a>. One must use the
hash algorithm appropriate in security level to the curve used, i.e., for curve
P-256 one uses SHA-256, and for curve P-384 one uses SHA-384.
          </p>

          <p>
The required inputs to this algorithm are a <em>transformed data document</em>
(<var>transformedDocument</var>) and a <em>canonical proof configuration</em>
(<var>canonicalProofConfig</var>). A single <em>hash data</em> value represented as
series of bytes is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>transformedDocumentHash</var> be the result of applying the SHA-256
(SHA-2 with 256-bit output) or SHA-384 (SHA-2 with 384-bit output)
cryptographic hashing algorithm [[RFC6234]] to the
respective curve P-256 or curve P-384 <var>transformedDocument</var>.
Respective <var>transformedDocumentHash</var> will be exactly 32 or 48 bytes
in size.
            </li>
            <li>
Let <var>proofConfigHash</var> be the result of applying the SHA-256
(SHA-2 with 256-bit output) or SHA-384 (SHA-2 with 384-bit output)
cryptographic hashing algorithm [[RFC6234]] to the
respective curve P-256 or curve P-384 <var>canonicalProofConfig</var>.
Respective <var>proofConfigHash</var> will be exactly 32 or 48 bytes in size.
            </li>
            <li>
Let <var>hashData</var> be the result of concatenating <var>proofConfigHash</var> (the
first hash) followed by <var>transformedDocumentHash</var> (the second hash).
            </li>
            <li>
Return <var>hashData</var> as the <em>hash data</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Proof Configuration (ecdsa-jcs-2019)</h4>

          <p>
The following algorithm specifies how to generate a
<em>proof configuration</em> from a set of <em>proof options</em>
that is used as input to the <a href="#hashing-ecdsa-jcs-2019">proof hashing algorithm</a>.
          </p>

          <p>
The required inputs to this algorithm are <em>proof options</em>
(<var>options</var>). The <em>proof options</em> MUST contain a type identifier
for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MUST contain a cryptosuite
identifier (<var>cryptosuite</var>). A <em>proof configuration</em>
object is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>proofConfig</var> be an empty object.
            </li>
            <li>
Set <var>proofConfig</var>.<var>type</var> to
<var>options</var>.<var>type</var>.
            </li>
            <li>
If <var>options</var>.<var>cryptosuite</var> is set, set
<var>proofConfig</var>.<var>cryptosuite</var> to its value.
            </li>
            <li>
If <var>options</var>.<var>type</var> is not set to `DataIntegrityProof` and
<var>proofConfig</var>.<var>cryptosuite</var> is not set to `ecdsa-jcs-2019`, an
`INVALID_PROOF_CONFIGURATION` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>created</var> to
<var>options</var>.<var>created</var>. If the value is not a valid
[[XMLSCHEMA11-2]] datetime, an `INVALID_PROOF_DATETIME` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>verificationMethod</var> to
<var>options</var>.<var>verificationMethod</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>proofPurpose</var> to
<var>options</var>.<var>proofPurpose</var>.
            </li>
            <li>
Let <var>canonicalProofConfig</var> be the result of applying the
JSON Canonicalization Scheme [[RFC8785]] to the <var>proofConfig</var>.
            </li>
            <li>
Return <var>canonicalProofConfig</var>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Proof Serialization (ecdsa-jcs-2019)</h4>

          <p>
The following algorithm specifies how to serialize a digital signature from
a set of cryptographic hash data. This
algorithm is designed to be used in conjunction with the algorithms defined
in the Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Algorithms</a>. Required inputs are
cryptographic hash data (<var>hashData</var>) and
<em>proof options</em> (<var>options</var>). The
<em>proof options</em> MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MAY contain a cryptosuite
identifier (<var>cryptosuite</var>). A single <em>digital proof</em> value
represented as series of bytes is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>privateKeyBytes</var> be the result of retrieving the
private key bytes associated with the
<var>options</var>.<var>verificationMethod</var> value as described in the
Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Retrieving Cryptographic Material</a>.
            </li>
            <li>
Let <var>proofBytes</var> be the result of applying the Elliptic Curve Digital
Signature Algorithm (ECDSA) [[FIPS-186-5]], with <var>hashData</var> as the data
to be signed using the private key specified by <var>privateKeyBytes</var>.
<var>proofBytes</var> will be exactly 64 bytes in size for a P-256 key, and
96 bytes in size for a P-384 key.
            </li>
            <li>
Return <var>proofBytes</var> as the <em>digital proof</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Proof Verification (ecdsa-jcs-2019)</h4>

          <p>
The following algorithm specifies how to verify a digital signature from
a set of cryptographic hash data. This
algorithm is designed to be used in conjunction with the algorithms defined
in the Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Algorithms</a>. Required inputs are
cryptographic hash data (<var>hashData</var>),
a digital signature (<var>proofBytes</var>), and
proof options (<var>options</var>). A <em>verification result</em>
represented as a boolean value is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>publicKeyBytes</var> be the result of retrieving the
public key bytes associated with the
<var>options</var>.<var>verificationMethod</var> value as described in the
Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Retrieving Cryptographic Material</a>.
            </li>
            <li>
Let <var>verificationResult</var> be the result of applying the verification
algorithm, Elliptic Curve Digital Signature Algorithm (ECDSA) [[FIPS-186-5]],
with <var>hashData</var> as the data to be verified against the
<var>proofBytes</var> using the public key specified by
<var>publicKeyBytes</var>.
            </li>
            <li>
Return <var>verificationResult</var> as the <em>verification result</em>.
            </li>
          </ol>

        </section>
      </section>

      <section>
        <h4>Selective Disclosure Functions</h4>

        <p class="issue" title="(AT RISK) Pending implementation feedback and security reviews.">
The Working Group is seeking implementer feedback on these generalized selective
disclosure functions as well as horizonal security review on the features from
parties at W3C and IETF. Those reviews might result in significant changes to
these functions, migration of these functions to the core Data Integrity
specification (for use by other cryptographic suites), or the removal of the
algorithm from the specification during the Candidate Recommendation phase.
        </p>

        <p>
The following section contains a set of functions that are used throughout
cryptographic suites that perform selective disclosure.
        </p>

        <section>
          <h4>labelReplacementCanonizeNQuads</h4>

          <p>
The following algorithm canonizes a JSON-LD document and replaces any blank
node identifiers in the canonicalized document using a label map factory
function, <var>labelMapFactoryFunction</var>. The required inputs are a JSON-LD
document (<var>document</var>) and a label map factory functon
(<var>labelMapFactoryFunction</var>). Any JSON-LD custom options (such as
a document loader) can also be passed. A N-Quads representation of the
<em>canonicalNQuads</em> as an array of N-Quad strings, with the replaced
blank node labels, and a map from the old blank node IDs to the new blank node
IDs, <em>labelMap</em>, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Deserialize the JSON-LD document to RDF, <var>rdf</var>, using the <a
href="https://www.w3.org/TR/json-ld11-api/#deserialize-json-ld-to-rdf-algorithm">
JSON-LD Deserialize to RDF algorithm</a>, passing any custom options (such
as a document loader).
            </li>
            <li>
Run the RDF Dataset Canonicalization Algorithm [[RDF-CANON]] on
<var>rdf</var>, passing any custom options, and get the canonicalized dataset
as output, which includes a canonical bnode identifier map,
<var>canonicalIdMap</var>.
            </li>
            <li>
Pass <var>canonicalIdMap</var> to <var>labelMapFactoryFunction</var> to produce
a new bnode identifier map, <em>labelMap</em>.
            </li>
            <li>
Use the canonicalized dataset and <em>labelMap</em> to produce canonical
N-Quads representation as an array of N-Quad strings, <em>canonicalNQuads</em>.
            </li>
            <li>
Return <em>labelMap</em> and <em>canonicalNQuads</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>labelReplacementCanonizeJsonLd</h4>

          <p>
The following algorithm deserializes a JSON-LD document to RDF and returns
the result of calling the algorithm in Section
<a href="#labelReplacementCanonizeNQuads"></a>. The required inputs are an
array of N-Quad strings (<var>nquads</var>), a label map factory functon
(<var>labelMapFactoryFunction</var>). Any custom options can also be passed. An
N-Quads representation of the <em>canonized result</em>, with the replaced
blank node labels, and a map from the old blank node IDs to the new blank node
IDs, <em>labelMap</em>, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Deserialize the JSON-LD document to RDF, <var>rdf</var>, using the <a
href="https://www.w3.org/TR/json-ld11-api/#deserialize-json-ld-to-rdf-algorithm">
JSON-LD Deserialize to RDF algorithm</a>, passing any custom options (such
as a document loader).
            </li>
            <li>
Serialize <var>rdf</var> to an array of N-Quad strings, <var>nquads</var>.
            </li>
            <li>
Return the result of calling the algorithm in Section
<a href="#labelReplacementCanonizeNQuads"></a>, passing <var>nquads</var>,
<var>labelMapFactoryFunction</var>, and any custom options.
            </li>
          </ol>

        </section>

        <section>
          <h4>createLabelMapFunction</h4>

          <p>
The following algorithm creates a label map factory function that uses an
input label map to replace canonical blank node identifiers with another
value. The required input is a label map, <var>labelMap</var>. A
function, <em>labelMapFactoryFunction</em>, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Create a function, <var>labelMapFactoryFunction</var>, with one required input:
a canonical node identifier map, <var>canonicalIdMap</var>, and that will
return a blank node identifier map, <em>bnodeIdMap</em> as output. Set the
function's implementation to:
              <ol class="algorithm">
                <li>
                  <li>
Generate a new empty bnode identifier map, <em>bnodeIdMap</em>.
                  </li>
                  <li>
For each map entry, <em>entry</em>, in <var>canonicalIdMap</var>:
                    <ol class="algorithm">
                      <li>
Use the canonical identifier from the value in <em>entry</em> as a key
in <var>labelMap</var> to get the new label, <em>newLabel</em>.
                      </li>
                      <li>
Add a new entry, <var>newEntry</var>, to <em>bnodeIdMap</em> using the key
from <em>entry</em> and <em>newLabel</em> as the value.
                      </li>
                    </ol>
                  </li>
                  <li>
Return <em>bnodeIdMap</em>.
                  </li>
                </li>
              </ol>
            </li>
            <li>
Return <var>labelMapFactoryFunction</var>.
            </li>
          </ol>

        </section>

        <section>
          <h4>createHmacIdLabelMapFunction</h4>

          <p>
The following algorithm creates a label map factory function that uses an
HMAC to replace canonical blank node identifiers with their encoded HMAC
digests. The required input is an HMAC (previously initialized with a
secret key), <var>HMAC</var>. A function, <em>labelMapFactoryFunction</em>, is
produced as output.
          </p>

          <ol class="algorithm">
            <li>
Create a function, <var>labelMapFactoryFunction</var>, with one required input:
a canonical node identifier map, <var>canonicalIdMap</var>, and that will
return a blank node identifier map, <em>bnodeIdMap</em> as output. Set the
function's implementation to:
              <ol class="algorithm">
                <li>
                  <li>
Generate a new empty bnode identifier map, <em>bnodeIdMap</em>.
                  </li>
                  <li>
For each map entry, <em>entry</em>, in <var>canonicalIdMap</var>:
                    <ol class="algorithm">
                      <li>
HMAC the canonical identifier from the value in <em>entry</em> to get an HMAC
digest, <em>digest</em>.
                      </li>
                      <li>
Generate a new string value, <em>b64urlDigest</em>, and initialize it to "u"
followed by appending a base64url-no-pad encoded version of the <em>digest</em>
value.
                      </li>
                      <li>
Add a new entry, <var>newEntry</var>, to <em>bnodeIdMap</em> using the key
from <em>entry</em> and <em>b64urlDigest</em> as the value.
                      </li>
                    </ol>
                  </li>
                  <li>
Return <em>bnodeIdMap</em>.
                  </li>
                </li>
              </ol>
            </li>
            <li>
Return <var>labelMapFactoryFunction</var>.
            </li>
          </ol>

          <p class="note" title="Other algorithms are possible">
A different primitive could be created that returned a label map factory
function that would instead sort the resulting HMAC digests and assign labels
in the produced label map using a prefix and integers based on their sorted
order instead. This primitive might be useful for selective disclosure schemes,
such as BBS, that favor unlinkability over minimizing unrevealed data leakage.
          </p>

        </section>

        <section>
          <h4>skolemize</h4>

          <p>
The following algorithm replaces all blank node identifiers in an array of
N-Quad statements with a URN. The required inputs are an array of N-Quad strings
(<var>inputNquads</var>) and a URN scheme (<var>urnScheme</var>). An array of
N-Quad strings, <em>skolemizedNquads</em>, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Create a new array of N-Quad strings, <em>skolemizedNquads</em>.
            </li>
            <li>
For each N-Quad string, <em>s1</em>, in the input array:
            <ol class="algorithm">
              <li>
Create a new string, <em>s2</em>, that is a copy of <em>s1</em> replacing any
occurrence of a blank node identifier with a URN ("urn:"), plus the input
custom scheme (<var>urnScheme</var>), plus a colon (":"), and
the value of the blank node identifier. For example, a regular expression
of a similar form to the following would achieve the desired result:
<code>s1.replace(/(_:([^\s]+))/g, '&lt;urn:custom-scheme:$2>')</code>.
              </li>
              <li>
Append <em>s2</em> to <em>skolemizedNquads</em>.
              </li>
            </ol>
            <li>
Return <em>skolemizedNquads</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>deskolemize</h4>

          <p>
The following algorithm replaces all custom scheme URNs in an array of
N-Quad statements with a blank node identifier. The required inputs are an array of N-Quad strings
(<var>inputNquads</var>) and a URN scheme (<var>urnScheme</var>). An array of
N-Quad strings, <em>deskolemizedNquads</em>, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Create a new array of N-Quad strings, <em>deskolemizedNquads</em>.
            </li>
            <li>
For each N-Quad string, <em>s1</em>, in the <var>inputNquads</var> array:
            <ol class="algorithm">
              <li>
Create a new string, <em>s2</em>, that is a copy of <em>s1</em> replacing any
occurrence of a URN ("urn:"), plus the input
custom scheme (<var>urnScheme</var>), plus a colon (":"), and
the value of the blank node identifier with a blank node prefix ("_:"), plus
the value of the blank node identifier. For example, a regular expression
of a similar form to the following would achieve the desired result:
<code>s1.replace(/(&lt;urn:custom-scheme:([^>]+)>)/g, '_:$2').</code>.
              </li>
              <li>
Append <em>s2</em> to <em>deskolemizedNquads</em>.
              </li>
            </ol>
            <li>
Return <em>deskolemizedNquads</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>toSkolemizedJSONLD</h4>

          <p>
The following algorithm converts an array of N-Quads to a skolemized
JSON-LD document. The required inputs are an array of N-Quad strings
(<var>inputNquads</var>). A JSON-LD document, <em>skolemizedJSONLD</em>, is
produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `skolemizedQuads` to the result of calling the algorithm in
Section <a href="#skolemize"></a>, with <var>inputNQuads</var> and
"custom-scheme" as parameters. Implementations MAY choose a different
<em>urnSchemeName</em> that is different than "custom-scheme" so long as the
same scheme name is used in the algorithm in Section
<a href="#todeskolemizedrdf"></a>.
            </li>
            <li>
Join `skolemizedQuads` into a single N-Quads string, `dataset`.
            </li>
            <li>
Set <em>skolemizedJSONLD</em> to the result of the
<a href="https://www.w3.org/TR/json-ld11-api/#serialize-rdf-as-json-ld-algorithm">
Serialize RDF as JSON-LD</a> algorithm, passing any custom options (such as a
document loader), to convert `dataset` from RDF to a JSON-LD document.
            </li>
            <li>
Return <em>skolemizedJSONLD</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>toDeskolemizedRDF</h4>

          <p>
The following algorithm converts a skolemized JSON-LD document, such as one
created using the algorithm in Section <a href="#toskolemizedjsonld"></a>, to an
array of deskolemized N-Quads. The required inputs are a JSON-LD document,
<em>skolemizedJSONLD</em>. An array of deskolemized N-Quad strings
(<var>outputNquads</var>) is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `skolemizedDataset` to the result of calling the
<a href="https://www.w3.org/TR/json-ld11-api/#deserialize-json-ld-to-rdf-algorithm">
Deserialize JSON-LD to RDF</a> algorithm, passing any custom options (such as a
document loader), to convert `skolemizedJSONLD` from JSON-LD to RDF in N-Quads
format.
            </li>
            <li>
Split `skolemizedDataset` into an array of individual N-Quads,
`skolemizedNquads`.
            </li>
            <li>
Set <var>outputNquads</var> to the result of calling the algorithm in Section
<a href="#deskolemize"></a> with `skolemizedNquads` and "custom-scheme" as
parameters. Implementations MAY choose a different <em>urnSchemeName</em> that
is different than "custom-scheme" so long as the same scheme name is used in
the algorithm in Section <a href="#toskolemizedjsonld"></a>.
            </li>
            <li>
Return <em>outputNquads</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>jsonPointerToPaths</h4>

          <p>
The following algorithm converts a JSON Pointer [[RFC6901]] to an array of paths
into a JSON tree. The required input is a JSON Pointer string
(<var>pointer</var>). An array of paths (<em>paths</em>) is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `paths` to an empty array.
            </li>
            <li>
Initialize `splitPath` to an array by splitting <var>pointer</var> on the
"/" character and skipping the first, empty, split element. In Javascript
notation, this step is equivalent to the following code:
`pointer.split('/').slice(1)`
            </li>
            <li>
For each `path` in `splitPath`:
              <ol class="algorithm">
                <li>
If `path` does not include `~`, then add `path` to `paths`, converting it to
an integer if it parses as one, leaving it as a string if it does not.
                </li>
                <li>
Otherwise, unescape any JSON pointer escape sequences in `path` and add the
result to `paths`.
                </li>
              </ol>
            </li>
            <li>
Return `paths`.
            </li>
          </ol>
        </section>

        <section>
          <h4>createInitialFrame</h4>

          <p>
The following algorithm creates an initial JSON-LD frame based on a JSON-LD
object. This is a helper function used within the algorithm in
Section <a href="#jsonpointerstoframe"></a>. The required input is a
JSON-LD object (<var>value</var>). A JSON-LD frame <em>frame</em> is produced
as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize <em>frame</em> to an empty object.
            </li>
            <li>
If <var>value</var> has an `id` that is not a blank node identifier, set
`frame.id` to its value. Note: All non-blank node identifiers in the path of
any JSON Pointer MUST be included in the frame, this includes any root document
identifier.
            </li>
            <li>
If <var>value</var>.`type` is set, set <em>frame</em>.`type` to its value.
Note: All `type`s in the path of any JSON Pointer MUST be included in the frame,
this includes any root document `type`.
            </li>
            <li>
Return <em>frame</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>jsonPointersToFrame</h4>

          <p>
The following algorithm converts an array of JSON Pointers and a JSON-LD
document to a JSON-LD Frame to be used on that specific document. The required
input is an array of JSON Pointers (<var>pointers</var>) and a JSON-LD document
(<var>document</var>). A JSON-LD frame (<em>frame</em>) is produced as output.
          </p>

          <ol class="algorithm">
            <li>
If `pointers` is empty, return `null`.
            </li>
            <li>
Initialize `frame` to an initial frame passing `document` as `value` to
the algorithm in Section <a href="#createinitialframe"></a>.
            </li>
            <li>
For each `pointer` in `pointers` walk the document from root to the pointer
target value building the frame:
            <ol class="algorithm">
              <li>
Initialize `parentFrame` to `frame`.
              </li>
              <li>
Initialize `parentValue` to `document`.
              </li>
              <li>
Initialize `value` to `parentValue`.
              </li>
              <li>
Initialize `valueFrame` to `parentFrame`.
              </li>
              <li>
Parse the `pointer` into an array of `paths` using the algorithm in
Section <a href="#jsonpointertopaths"></a>.
              </li>
              <li>
For each `path` in `paths`:
                <ol class="algorithm">
                  <li>
Set `parentFrame` to `valueFrame`.
                  </li>
                  <li>
Set `parentValue` to `value`.
                  </li>
                  <li>
Set `value` to `parentValue[path]`. If `value` is now undefined, throw an error
indicating that the JSON pointer does not match the given `document`.
                  </li>
                  <li>
Set `valueFrame` to `parentFrame[path]`.
                  </li>
                  <li>
If `valueFrame` is undefined:
                    <ol class="algorithm">
                      <li>
If `value` is an array, set `valueFrame` to an empty array.
                      </li>
                      <li>
Otherwise, set `valueFrame` to an initial frame passing `value` to
the algorithm in Section <a href="#createinitialframe"></a>.
                      </li>
                      <li>
Set `parentFrame[path]` to `valueFrame`.
                      </li>
                    </ol>
                  </li>
                </li>
              <li>
Note: Next we generate the final `valueFrame`.
              </li>
              <li>
If `value` is not an object, then a literal has been selected: Set `valueFrame`
to `value`.
              </li>
              <li>
Otherwise, if `value` is an array: Set `valueFrame` to the result of mapping
every element in `value` to a deep copy of itself. If any element in `value` is
also an `array`, throw an error indicating that arrays of arrays are not
supported.
              </li>
              <li>
Otherwise: Set `valueFrame` to an object that merges a shallow copy of
`valueFrame` with a deep copy of `value`, e.g., `{...valueFrame,
&hellip;deepCopy(value)}`.
              </li>
              <li>
If `paths` has a length of zero, then the whole `document` has been selected by
the `pointer`: Set `frame` to `valueFrame`.
              </li>
              <li>
Otherwise, a partial selection has been made by the pointer:
                <ol class="algorithm">
                  <li>
Get the last `path`, `lastPath`, from `paths`.
                  </li>
                  <li>
Set `parentFrame[lastPath]` to `valueFrame`.
                  </li>
                </ol>
              <li>
Set `frame['@context']` to a deep copy of `document['@context']`.
              </li>
              <li>
Return `frame`.
              </li>
            </ol>
          </ol>
        </section>

        <section>
          <h4>strictFrame</h4>

          <p>
The following algorithm performs a JSON-LD framing operation on a JSON-LD
document with strict framing options. The required inputs are a JSON-LD Document
(<var>document</var>) and a JSON-LD Frame (<var>frame</var>). A JSON-LD document
(<em>framedDocument</em>) is generated as output.
          </p>

          <ol class="algorithm">
            <li>
Set <em>framedDocument</em> to the result of the
<a href="https://www.w3.org/TR/json-ld11-framing/#framing">
JSON-LD Framing algorithm</a>, passing `document` and `frame`, and setting the
options `requireAll`, `explicit`, and `omitGraph` to `true`. Any additional
custom options passed, such as a document loader, is included as well.
            </li>
            <li>
Return <em>framedDocument</em>.
            </li>
          </ol>
        </section>

        <section>
          <h4>groupNquads</h4>

          <p>
The following algorithm groups N-Quads into matching and non-matching groups.
The inputs are an array of N-Quads (<var>nquads</var>, an optional skolemized
JSON-LD document (<var>skolemizedDocument</var>), an optional JSON-LD frame
(<var>frame</var>) , and any options, such as a document loader, to be passed to
JSON-LD APIs. Each of the output groups (matching and non-matching) are
expressed as a map that maps an index into <var>nquads<var> to the N-Quad value.
This algorithm uses a JSON-LD frame to match specific N-Quads in the array of
given <var>nquads</var>. It internally skolemizes and then deskolemizes any
blank nodes around the framing operation to ensure blank node identifiers do not
change, preventing the matching operation from working properly.
An object containing a <em>matching</em> and <em>nonmatching</em> arrays of
N-Quads are generated as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `matching` to an empty map.
            </li>
            <li>
Initialize `nonMatching` to an empty map.
            </li>
            <li>
If `frame` is not given or `null`, then there are no matches so:
              <ol class="algorithm">
                <li>
Add each entry (index, element) in `nquads` to `nonMatching`.
                </li>
                <li>
Return an object with "matching" set to `matching` and "nonMatching" set to
`nonMatching`.
                </li>
              </ol>
            </li>
            <li>
If `skolemizedDocument` has not been given: Set `skolemizedDocument` to the
result of calling "createSkolemizedDocument", passing `nquads` and any custom
JSON-LD API options (such as a document loader).
            </li>
            <li>
Initialize `framed` to the result of calling "strictFrame", passing
`skolemizedDocument`, `frame`, and any custom JSON-LD API options. Note: This
step filters the skolemized document to get only data that matches the frame as
a new JSON-LD document.
            </li>
            <li>
Initialize `matchingDeskolemized` to the result of calling "toDeskolemizedRDF",
passing `framed` and any custom JSON-LD API options. Note: This step converts
any matching data back to deskolemized N-Quads, matching their original
expression.
            </li>
            <li>
For each entry (`index`, `nq`) in `nquads`:
              <ol class="algorithm">
                <li>
If `matchingDeskolemized` includes `nq`, add the entry to `matching`.
                </li>
                <li>
Otherwise, add the entry to `nonMatching`.
                </li>
              </ol>
            </li>
            <li>
Return an object with "matching" set to `matching` and "nonMatching" set to
`nonMatching`.
            </li>
          </ol>
        </section>

        <section>
          <h4>filterAndGroupNquads</h4>

          <p>
The following algorithm filters N-Quads, given in an array of N-Quads and a
JSON-LD filtering frame, and then groups the N-Quads that passed the filter into
matching and non-matching groups based on another JSON-LD grouping frame. This
function will internally perform skolemization and deskolemization around
framing operations to ensure that any blank node identifiers do not change,
which would prevent filtering and matching operations from working properly. The
inputs to the algorithm are an array of N-Quads (<var>nquads</var>), a JSON-LD
filtering frame (<var>filterFrame</var>), a JSON-LD grouping frame
(<var>groupFrame</var>). Additionally, any custom JSON-LD API options are
expected to be given as an input. An object containing two properties is
provided as output; <em>matching</em> and <em>nonmatching</em> each hold arrays
of their associated N-Quads.
          </p>

          <ol class="algorithm">
            <li>
Initialize `skolemizedDocument` to the result of calling the algorithm in
Section <a href="#toskolemizedjsonld"></a>, passing `nquads` and any custom
JSON-LD API options (such as a document loader).
            </li>
            <li>
Initialize `filteredDocument` to the result of calling the algorithm in Section
<a href="#strictframe"></a>, passing `skolemizedDocument`, `filterFrame`, and
any custom JSON-LD API options.
            </li>
            <li>
Initialize `filteredNQuads` to the result of calling the algorithm in Section <a
href="#todeskolemizedrdf"></a>, passing `filteredDocument` and any custom
JSON-LD API options.
            </li>
            <li>
Note: These next two steps can be performed in parallel.
              <ol class="algorithm">
                <li>
  Get the canonical blank node identifier map, `canonicalIdMap`, by calling
  [[RDF-CANON]], passing the joined `filteredNQuads`. Canonicalize `filteredNQuads
  Note: These two steps can be performed in parallel.
                </li>
                <li>
  Get the `groupResult` by calling the algorithm in Section
  <a href="#groupnquads"></a>, passing `filteredNQuads`, `filteredDocument`,
  `groupFrame`, and any custom JSON-LD API options.
                </li>
              </ol>
            </li>
            <li>
Note: Next generate matching and non-matching maps composed of original indexes
to original N-Quads. The `groupResult` is different; it contains matching and
non-matching maps using the `filteredNQuads` indexes. Both maps of indexes are
useful to callers.
            </li>
            <li>
Initialize `matching` to a new map.
            </li>
            <li>
Initialize `nonMatching` to a new map.
            </li>
            <li>
Initialize filteredMatches to the values in `groupResult.matching`.
            </li>
            <li>
Initialize filteredNonMatches to the values in `groupResult.nonMatching`.
            </li>
            <li>
For each entry (`index`, `nq`) in `nquads`:
              <ol class="algorithm">
                <li>
If `filteredMatches` includes `nq` then add the entry to `matching`.
                </li>
                <li>
Otherwise, if `filteredNonMatching` includes `nq` then add the entry to
`nonMatching`.
                </li>
              </ol>
            </li>
            <li>
Initialize `labelMap` to the reverse of `canonicalIdMap`. `labelMap` uses
canonical blank node identifiers as keys and original blank node identifiers as
values.
            </li>
            <li>
Return an object with "filtered" set to `groupResult`, "labelMap" set to
`labelMap`, "matching" to `matching`, and "nonMatching" to `nonMatching`.
            </li>
          </ol>
        </section>

        <section>
          <h4>hashMandatoryNQuads</h4>

          <p>
The following algorithm cryptographically hashes an array of mandatory to
disclose N-Quads using a provided hashing API. The required input is an array of
mandatory to disclose N-Quads (<var>mandatory</var>) and a hashing function
(<var>hasher</var>). A cryptographic hash (<em>mandatoryHash</em>) is produced
as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `bytes` to the UTF-8 representation of the joined `mandatory`
N-Quads.
            </li>
            <li>
Initialize `mandatoryHash` to the result of using `hasher` to hash `bytes`.
            </li>
            <li>
Return `mandatoryHash`.
            </li>
          </ol>
        </section>
      </section>


      <section>
        <h3>ecdsa-sd-2023 Functions</h3>

        <p class="issue" title="(AT RISK) Pending implementation feedback and security reviews.">
The Working Group is seeking implementer feedback on these cryptographic suite
functions as well as horizonal security review on the feature from parties at
W3C and IETF. Those reviews might result in significant changes to these
algorithms, or the removal of the algorithms from the specification during the
Candidate Recommendation phase.
        </p>

        <p>
This section contains subalgorithms that are useful to the `ecdsa-sd-2023`
cryptographic suite.
        </p>

        <section>
          <h4>serializeSignData</h4>

          <p>
The following algorithm serializes the data that is to be signed by the private
key associated with the base proof verification method. The required inputs are
the proof options hash (<var>proofHash</var>), the proof-scoped multikey-encoded
public key (<var>publicKey</var>), and the mandatory hash
(<var>mandatoryHash</var>). A single <em>sign data</em> value,
represented as series of bytes, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Return the concatenation of <var>proofHash</var>, <var>publicKey</var>, and
<var>mandatoryHash</var>, in that order, as <em>sign data</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>serializeBaseProofValue</h4>

          <p>
The following algorithm serializes the base proof value, including the
base signature, public key, HMAC key, signatures, and mandatory pointers.
The required inputs are a base signature <var>baseSignature</var>, a public key
<var>publicKey</var>, an HMAC key <var>hmacKey</var>, an array of
<var>signatures</var>, and an array of <var>mandatoryPointers</var>.
A single <em>base proof</em> string value is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize a byte array, `proofValue`, that starts with the ECDSA-SD base proof
header bytes 0xd9, 0x5d, and 0x00.
            </li>
            <li>
Initialize `components` to an array with five elements containing the values of:
`baseSignature`, `publicKey`, `hmacKey`, `signatures`, and `mandatoryPointers`.
            </li>
            <li>
CBOR-encode `components` and append it to `proofValue`.
            </li>
            <li>
Initialize `baseProof` to a string with the multibase-base64url-no-pad-encoding
of `proofValue`. That is, return a string starting with "u" and ending with the
base64url-no-pad-encoded value of `proofValue`.
            </li>
            <li>
Return `baseProof` as <em>base proof</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>parseBaseProofValue</h4>

          <p>
The following algorithm parses the components of an `ecdsa-sd-2023` selective
disclosure base proof value. The required inputs are a proof value
(<var>proofValue</var>). A single object <em>parsed base proof</em>, containing
five elements, using the names "baseSignature", "publicKey", "hmacKey",
"signatures", and "mandatoryPointers", is produced  as output.
          </p>

          <ol class="algorithm">
            <li>
Ensure the `proofValue` string starts with `u`, indicating that it is a
multibase-base64url-no-pad-encoded value, throwing an error if it does not.
            </li>
            <li>
Initialize `decodedProofValue` to the result of base64url-no-pad-decoding the
substring after the leading `u` in `proofValue`.
            </li>
            <li>
Ensure that the `decodedProofValue` starts with the ECDSA-SD base proof header
bytes 0xd9, 0x5d, and 0x00, throwing an error if it does not.
            </li>
            <li>
Initialize `components` to an array that is the result of CBOR-decoding the
bytes that follow the three-byte ECDSA-SD base proof header. Ensure the result
is an array of five elements.
            </li>
            <li>
Return an object with properties set to the five elements, using the names
"baseSignature", "publicKey", "hmacKey", "signatures", and "mandatoryPointers",
respectively.
            </li>
          </ol>

        </section>

        <section>
          <h4>createDisclosureData</h4>

          <p>
The following algorithm creates data to be used to generate a derived proof. The
inputs include a JSON-LD document (<var>document</var>), an ECDSA-SD base proof
(<var>proof</var>), an array of JSON pointers to use to selectively disclose
statements (<var>selectivePointers</var>), and any custom JSON-LD API options,
such as a document loader). A single object, <em>disclosure data</em>, is
produced as output, which contains the "baseSignature", "publicKey",
"signatures" for "filteredSignatures", "labelMap", "mandatoryIndexes", and
"revealDocument" fields.
          </p>

          <ol class="algorithm">
            <li>
Initialize `baseSignature`, `publicKey`, `hmacKey`, `signatures`, and
`mandatoryPointers` to the values of the associated properties in the object
returned when calling the algorithm in Section
<a href="#parsebaseproofvalue"></a>, passing the `proofValue` from `proof`.
            </li>
            <li>
Initialize `hmac` to an HMAC API using `hmacKey`. The HMAC uses the same hash
algorithm used in the signature algorithm, i.e., SHA-256 for a P-256 curve.
            </li>
            <li>
Initialize `nquads` to the result of calling the algorithm in Section
<a href="#hmacidcanonize"></a>, passing `document`, `hmac`, and any custom
JSON-LD API options as parameters. Note: This step transforms the document into
an array of canonical N-Quads with pseudorandom blank node identifiers based on
`hmac`.
            </li>
            <li>
Initialize `mandatoryFrame` to the result of calling the algorithm in Section <a
href="#jsonpointerstoframe"></a>, passing `document` and `mandatoryPointers` as
`pointers`.
            </li>
            <li>
Initialize `combinedFrame` to the result of calling the
<a href="#jsonpointerstoframe"></a> primitive, passing `document` and the
concatenation of `mandatoryPointers` and `selectivePointers` as `pointers`.
            </li>
            <li>
If `mandatoryFrame` and `combinedFrame` are both `null`, then throw an error
indicating that nothing is to be disclosed.
            </li>
            <li>
Execute the following two steps in parallel (if the runtime environment allows
for parallel execution, otherwise, execute the operations serially):
              <ol class="algorithm">
                <li>
Initialize `revealDocument` to the result of calling the algorithm in
Section <a href="#strictframe"></a>, passing `document`, `combinedFrame` as
`frame`, and any custom JSON-LD API options.
                </li>
                <li>
Initialize `filterAndGroupResult` to the result of calling the algorithm in
Section <a href="#filterandgroupnquads"></a>, passing `nquads`, `combinedFrame` for
`filterFrame`, `mandatoryFrame` for `groupFrame`, and any custom JSON-LD API
options.
                </li>
              </ol>
            </li>
            <li>
Initialize `labelMap` to the value of "labelMap" in `filterAndGroupResult`.
            </li>
            <li>
Initialize `relativeMandatory` to the value of "matching" in the value of
"filtered" in `filterAndGroupResult`.
            </li>
            <li>
Initialize `absoluteMandatory` to the value of "matching" in
`filterAndGroupResult`.
            </li>
            <li>
Initialize `absoluteNonMandatory` to the value of "nonMatching" in
`filterAndGroupResult`.
            </li>
            <li>
Initialize `mandatoryIndexes` to the keys from `relativeMandatory`.
            </li>
            <li>
Choose the signatures that match the selectively disclosed statements, which
requires shifting by any absolute mandatory indexes to cause the indexes in
`signatures` to match with `absoluteNonMandatory` map keys:
              <ol class="algorithm">
                <li>
Initialize `index` to `0`.
                </li>
                <li>
Initialize `filteredSignatures` to an empty array.
                </li>
                <li>
For each `signature` in `signatures`:
                  <ol class="algorithm">
                    <li>
While `index` is in `absoluteMandatory`, increment `index`.
                    </li>
                    <li>
If `index` is in `absoluteNonMandatory`, add `signature` to
`filteredSignatures`.
                    </li>
                    <li>
Increment `index`.
                    </li>
                  </ol>
                </li>
              </ol>
            </li>
            <li>
Return an object with properties matching `baseSignature`, `publicKey`,
"signatures" for `filteredSignatures`, `labelMap`, `mandatoryIndexes`, and
`revealDocument`.
            </li>
          </ol>

        </section>

        <section>
          <h4>compressLabelMap</h4>

          <p>
The following algorithm compresses a label map. The required inputs are
label map (<var>labelMap</var>). The output is a <em>compressed label map</em>.
          </p>

          <ol class="algorithm">
            <li>
Initialize `map` to an empty map.
              </li>
              <li>
For each entry (`k`, `v`) in `labelMap`:
                <ol class="algorithm">
                  <li>
Add an entry to `map` with a key that is a base-10 integer parsed from the
characters following the "c14n" prefix in `k` and a value that is a byte array
resulting from base64url-no-pad-decoding the characters after the "u" prefix in
                `v`.
                  </li>
                </ol>
              <li>
Return `map` as <em>compressed label map</em>.
              </li>
          </ol>

        </section>

        <section>
          <h4>decompressLabelMap</h4>

          <p>
The following algorithm decompresses a label map. The required input is a
compressed label map (<var>compressedLabelMap</var>). The output is a
<em>decompressed label map</em>.
          </p>

          <ol class="algorithm">
            <li>
Initialize `map` to an empty map.
              </li>
              <li>
For each entry (`k`, `v`) in `compressedLabelMap`:
                <ol class="algorithm">
                  <li>
Add an entry to `map` with a key that adds the prefix "c14n" to `k` and a value
that adds a prefix of "u" to the base64url-no-pad-encoded value for `v`.
                  </li>
                </ol>
              <li>
Return `map` as <em>decompressed label map</em>.
              </li>
          </ol>

        </section>

        <section>
          <h4>serializeDerivedProofValue</h4>

          <p>
The following algorithm serializes a derived proof value. The required inputs
are a base signature (<var>baseSignature</var>), public key
(<var>publicKey</var>), an array of signatures (<var>signatures</var>), a label
map (<var>labelMap</var>), and an array of mandatory indexes
(<var>mandatoryIndexes</var>). A single <em>derived proof</em> value, serialized
as a byte string, is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `compressedLabelMap` to the result of calling the algorithm in
Section <a href="#compresslabelmap"></a>, passing `labelMap` as the parameter.
            </li>
            <li>
Initialize a byte array, `proofValue`, that starts with the ECDSA-SD disclosure
proof header bytes `0xd9`, `0x5d`, and `0x01`.
            </li>
            <li>
Initialize `components` to an array with five elements containing the values of:
`baseSignature`, `publicKey`, `signatures`, `compressedLabelMap`, and
`mandatoryIndexes`.
            </li>
            <li>
CBOR-encode `components` and append it to `proofValue`.
            </li>
            <li>
Return the <em>derived proof</em> as a string with the
multibase-base64url-no-pad-encoding of `proofValue`. That is, return a string
starting with "u" and ending with the base64url-no-pad-encoded value of
`proofValue`.
            </li>
          </ol>

        </section>

        <section>
          <h4>parseDerivedProofValue</h4>

          <p>
The following algorithm parses the components of the derived proof value.
The required inputs are a derived proof value (<var>proofValue</var>). A
A single <em>derived proof value</em> value object is produced as output, which
contains a set to five elements, using the names "baseSignature", "publicKey",
"signatures", "labelMap", and "mandatoryIndexes".
          </p>

          <ol class="algorithm">
            <li>
Ensure the `proofValue` string starts with `u`, indicating that it is a
multibase-base64url-no-pad-encoded value, throwing an error if it does not.
            </li>
            <li>
Initialize `decodedProofValue` to the result of base64url-no-pad-decoding the
substring after the leading `u` in `proofValue`.
            </li>
            <li>
Ensure that the `decodedProofValue` starts with the ECDSA-SD disclosure proof
header bytes `0xd9`, `0x5d`, and `0x01`, throwing an error if it does not.
            </li>
            <li>
Initialize `components` to an array that is the result of CBOR-decoding the
bytes that follow the three-byte ECDSA-SD disclosure proof header. Ensure the
result is an array of five elements. Ensure the result is an array of five
elements: a byte array of length 64, a byte array of length 36, an array of byte
arrays, each of length 64, a map of integers to byte arrays of length 32, and an
array of integers, throwing an error if not.
            </li>
            <li>
Replace the fourth element in `components` using the result of calling the
algorithm in Section <a href="#decompresslabelmap"></a>, passing the existing
fourth element of `components` as `compressedLabelMap`.
            </li>
            <li>
Return <em>derived proof value</em> as an object with properties set to the five
elements, using the names "baseSignature", "publicKey", "signatures",
"labelMap", and "mandatoryIndexes", respectively.
            </li>
          </ol>

        </section>

        <section>
          <h4>createVerifyData</h4>

          <p>
The following algorithm creates the data needed to perform verification of an
ECDSA-SD-protected <a>verifiable credential</a>. The inputs include a JSON-LD
document (<var>document</var>), an ECDSA-SD disclosure proof (<var>proof</var>),
and any custom JSON-LD API options, such as a document loader. A single
<em>verify data</em> object value is produced as output containing the following
fields: "baseSignature", "proofHash", "publicKey", "signatures", "nonMandatory",
and "mandatoryHash".
          </p>

          <ol class="algorithm">
            <li>
Initialize `proofHash` to the result of perform RDF Dataset Canonicalization
[[RDF-CANON]] on the proof options. The hash used is the same as the one used in
the signature algorithm, i.e., SHA-256 for a P-256 curve. Note: This step can be
performed in parallel; it only needs to be completed before this algorithm needs
to use the `proofHash` value.
            </li>
            <li>
Initialize `baseSignature`, `publicKey`, `signatures`, `labelMap`, and
`mandatoryIndexes`, to the values associated with their property names in the
object returned when calling the algorithm in Section
<a href="#parsederivedproofvalue"></a>, passing `proofValue` from `proof`.
            </li>
            <li>
Initialize `nquads` to the result of calling the "labelReplacementCanonize"
primitive, passing `document`, the result of calling the "labelMapCanonize"
primitive (passing `labelMap`) as `labelReplacementFunction`, and any custom
JSON-LD API options. Note: This step transforms the document into an array of
canonical N-Quads with pseudorandom blank node identifiers based on `labelMap`.
            </li>
            <li>
Initialize `mandatory` to an empty array.
            </li>
            <li>
Initialize `nonMandatory` to an empty array.
            </li>
            <li>
For each entry (`index`, `nq`) in `nquads`, separate the N-Quads into mandatory
and non-mandatory categories:
            <ol class="algorithm">
              <li>
If `mandatoryIndexes` includes `index`, add `nq` to `mandatory`.
              </li>
              <li>
Otherwise, add `nq` to `nonMandatory`.
              </li>
            </ol>
            <li>
Initialize `mandatoryHash` to the result of calling the "hashMandatory"
primitive, passing `mandatory`.
            </li>
            <li>
Return an object with properties matching `baseSignature`, `proofHash`,
`publicKey`, `signatures`, `nonMandatory`, and `mandatoryHash`.
            </li>
          </ol>

        </section>

      </section>

      <section>
        <h3>ecdsa-sd-2023</h3>

        <p class="issue" title="(AT RISK) Pending implementation feedback and security reviews.">
The Working Group is seeking implementer feedback on this cryptographic suite
as well as horizonal security review on the feature from parties at W3C and
IETF. Those reviews might result in significant changes to this algorithm, or
the removal of the algorithm from the specification during the Candidate
Recommendation phase.
        </p>

        <p>
The `ecdsa-sd-2023` cryptographic suite takes an input document, canonicalizes
the document using the Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]], and then cryptographically hashes and signs the output
resulting in the production of a data integrity proof. The algorithms in this
section also include the verification of such a data integrity proof.
        </p>

        <section>
          <h4>Add Base Proof (ecdsa-sd-2023)</h4>

          <p>
To generate a base proof, the algorithm in
<a href="https://www.w3.org/TR/vc-data-integrity/#add-proof">
Section 4.1: Add Proof</a> in the Data Integrity
[[VC-DATA-INTEGRITY]] specification MUST be executed.
For that algorithm, the cryptographic suite specific
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-transformation-algorithm">
transformation algorithm</a> is defined in Section
<a href="#base-proof-transformation-ecdsa-sd-2023"></a>, the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-hashing-algorithm">
hashing algorithm</a> is defined in Section <a href="#base-proof-hashing-ecdsa-sd-2023"></a>,
and the
<a href="https://www.w3.org/TR/vc-data-integrity/#dfn-proof-serialization-algorithm">
proof serialization algorithm</a> is defined in Section
<a href="#base-proof-serialization-ecdsa-sd-2023"></a>.
          </p>
        </section>

        <section>
          <h4>Base Proof Transformation (ecdsa-sd-2023)</h4>

          <p>
The following algorithm specifies how to transform an unsecured input document
into a transformed document that is ready to be provided as input to the
hashing algorithm in Section <a href="#base-proof-hashing-ecdsa-sd-2023"></a>.
          </p>

          <p>
Required inputs to this algorithm are an
<a data-cite="vc-data-integrity#dfn-unsecured-data-document">
unsecured data document</a> (<var>unsecuredDocument</var>) and
transformation options (<var>options</var>). The
transformation options MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>), a cryptosuite
identifier (<var>cryptosuite</var>), and a verification method
(<var>verificationMethod</var>). The transformation options MUST contain an
array of mandatory JSON pointers (<var>mandatoryPointers</var>) and MAY contain
additional options, such as a JSON-LD document loader. A <em>transformed data
document</em> is produced as output. Whenever this algorithm encodes strings, it
MUST use UTF-8 encoding.
          </p>

          <ol class="algorithm">
            <li>
Initialize `hmac` to an HMAC API using a locally generated and exportable HMAC
key. The HMAC uses the same hash algorithm used in the signature algorithm,
which is detected via the <var>verificationMethod</var> provided to the
function. i.e., SHA-256 for a P-256 curve.
            </li>
            <li>
Initialize `nquads` to the result of calling the algorithm in Section
<a href="#labelreplacementcanonize"></a>, passing `unsecuredDocument`, the
result of calling the algorithm in Section
<a href="#labelmapcanonize"></a> (passing `hmac`) as the
`labelReplacementFunction`, and any custom JSON-LD API options. Note: This step
transforms the document into an array of canonical N-Quads with pseudorandom
blank node identifiers based on `hmac`.
            </li>
            <li>
Initialize `mandatoryFrame` to the result of calling the algorithm in Section
<a href="#jsonpointerstoframe"></a>, passing `document` and `mandatoryPointers` as
`pointers`.
            </li>
            <li>
Initialize `matching` and `nonMatching` to the result of calling the algorithm
in Section <a href="#groupnquads"></a>, passing `nquads`, `mandatoryFrame` as
`frame`, and any custom JSON-LD API options. Note: This step separates the
N-Quads to mandatory (to disclose) and non-mandatory groups.
            </li>
            <li>
Initialize `mandatory` to the values in the `matching` map.
            </li>
            <li>
Initialize `nonMandatory` to the values in the `nonMatching` map.
            </li>
            <li>
Initialize `hmacKey` to the result of exporting the HMAC key from `hmac`.
            </li>
            <li>
Return an object with "mandatoryPointers" set to `mandatoryPointers`,
"mandatory" set to `mandatory`, "nonMandatory" set to `nonMandatory`,
and "hmacKey" set to `hmacKey`.
            </li>
          </ol>
        </section>

        <section>
          <h4>Base Proof Hashing (ecdsa-sd-2023)</h4>

          <p>
The following algorithm specifies how to cryptographically hash a
<em>transformed data document</em> and <em>proof configuration</em>
into cryptographic hash data that is ready to be provided as input to the
algorithms in Section <a href="#base-proof-serialization-ecdsa-sd-2023"></a>.
          </p>

          <p>
The required inputs to this algorithm are a <em>transformed data document</em>
(<var>transformedDocument</var>) and <em>canonical proof configuration</em>
(<var>canonicalProofConfig</var>). A <em>hash data</em> value represented
as an object is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `proofHash` to the result of calling the RDF Dataset Canonicalization
algorithm [[RDF-CANON]] on `canonicalProofConfig` and then cryptographically
hashing the result using the same hash that is used by the signature algorithm,
i.e., SHA-256 for a P-256 curve. Note: This step can be performed in parallel;
it only needs to be completed before this algorithm terminates as the result is
part of the return value.
            </li>
            <li>
Initialize `mandatoryHash` to the result of calling the the algorithm in Section
<a href="#hashmandatorynquads"></a>, passing
<var>transformedDocument</var>.`mandatory`.
            </li>
            <li>
Initialize `hashData` as a deep copy of <var>transformedDocument</var> and
add `proofHash` as "proofHash" and `mandatoryHash` as "mandatoryHash" to that
object.
            </li>
            <li>
Return `hashData` as <em>hash data</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Base Proof Configuration (ecdsa-sd-2023)</h4>

          <p>
The following algorithm specifies how to generate a
<em>proof configuration</em> from a set of <em>proof options</em>
that is used as input to the
<a href="#base-proof-hashing-ecdsa-sd-2023">base proof hashing algorithm</a>.
          </p>

          <p>
The required inputs to this algorithm are <em>proof options</em>
(<var>options</var>). The <em>proof options</em> MUST contain a type identifier
for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MUST contain a cryptosuite
identifier (<var>cryptosuite</var>). A <em>proof configuration</em>
object is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Let <var>proofConfig</var> be an empty object.
            </li>
            <li>
Set <var>proofConfig</var>.<var>type</var> to
<var>options</var>.<var>type</var>.
            </li>
            <li>
If <var>options</var>.<var>cryptosuite</var> is set, set
<var>proofConfig</var>.<var>cryptosuite</var> to its value.
            </li>
            <li>
If <var>options</var>.<var>type</var> is not set to `DataIntegrityProof` and
<var>proofConfig</var>.<var>cryptosuite</var> is not set to `ecdsa-sd-2023`, an
`INVALID_PROOF_CONFIGURATION` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>created</var> to
<var>options</var>.<var>created</var>. If the value is not a valid
[[XMLSCHEMA11-2]] datetime, an `INVALID_PROOF_DATETIME` error MUST be raised.
            </li>
            <li>
Set <var>proofConfig</var>.<var>verificationMethod</var> to
<var>options</var>.<var>verificationMethod</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>proofPurpose</var> to
<var>options</var>.<var>proofPurpose</var>.
            </li>
            <li>
Set <var>proofConfig</var>.<var>@context</var> to
<var>unsecuredDocument</var>.<var>@context</var>.
            </li>
            <li>
Let <var>canonicalProofConfig</var> be the result of applying the
Universal RDF Dataset Canonicalization Algorithm
[[RDF-CANON]] to the <var>proofConfig</var>.
            </li>
            <li>
Return <var>canonicalProofConfig</var>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Base Proof Serialization (ecdsa-sd-2023)</h4>

          <p>
The following algorithm specifies how to create a base proof; called by an
issuer of an ECDSA-SD-protected Verifiable Credential. The base proof is to be
given only to the holder, who is responsible for generating a derived proof from
it, exposing only selectively disclosed details in the proof to a verifier. This
algorithm is designed to be used in conjunction with the algorithms defined
in the Data Integrity [[VC-DATA-INTEGRITY]] specification,
<a data-cite="vc-data-integrity#algorithms">
Section 4: Algorithms</a>. Required inputs are
cryptographic hash data (<var>hashData</var>) and
<em>proof options</em> (<var>options</var>). The
<em>proof options</em> MUST contain a type identifier for the
<a data-cite="vc-data-integrity#dfn-cryptosuite">
cryptographic suite</a> (<var>type</var>) and MAY contain a cryptosuite
identifier (<var>cryptosuite</var>). A single <em>digital proof</em> value
represented as series of bytes is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `proofHash`, `mandatoryPointers`, `mandatoryHash`, `nonMandatory`,
and `hmacKey` to the values associated with their property names
<var>hashData</var>.
            </li>
            <li>
Initialize `proofScopedKeyPair` to a locally generated P-256 ECDSA key pair.
Note: This key pair is scoped to the specific proof; it is not used for anything
else and the private key will be destroyed when this algorithm terminates.
            </li>
            <li>
Initialize `signatures` to an array where each element holds the result of
digitally signing the UTF-8 representation of each N-Quad string in
`nonMandatory`, in order. The digital signature algorithm is ES256, i.e., uses a
P-256 curve over a SHA-256 digest, and uses the private key from
`proofScopedKeyPair`. Note: This step generates individual signatures for each
statement that can be selectively disclosed using a local, proof-scoped key pair
that binds them together; this key pair will be bound to the proof by a
signature over its public key using the private key associated with the base
proof verification method.
            </li>
            <li>
Initialize `publicKey` to the multikey expression of the public key exported
from `proofScopedKeyPair`. That is, an array of bytes starting with the bytes
0x80 and 0x24 (which is the multikey p256-pub header (0x1200) expressed as a
varint) followed by the compressed public key bytes (the compressed header with
`2` for an even `y` coordinate and `3` for an odd one followed by the `x`
coordinate of the public key).
            </li>
            <li>
Initialize `toSign` to the result of calling the algorithm in Section
<a href="#serializesigndata"></a>, passing `proofHash`, `publicKey`, and
`mandatoryHash` as parameters to the algorithm.
            </li>
            <li>
Initialize `baseSignature` to the result of digitally signing `toSign` using the
private key associated with the base proof verification method.
            </li>
            <li>
Initialize `proofValue to the result of calling the algorithm in Section
<a href="#serializebaseproofvalue"></a>, passing `baseSignature`,
`publicKey`, `hmacKey`, `signatures`, and `mandatoryPointers` as parameters
to the algorithm.
            </li>
            <li>
Return `proofValue` as <em>digital proof</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Add Derived Proof (ecdsa-sd-2023)</h4>

          <p>
The following algorithm creates a selective disclosure derived proof; called by
a holder of an `ecdsa-sd-2023`-protected <a>verifiable credential</a>.
The derived proof is to be given to the <a>verifier</a>. The inputs include a
JSON-LD document (<var>document</var>), an ECDSA-SD base proof
(<var>proof</var>), an array of JSON pointers to use to selectively disclose
statements (<var>selectivePointers</var>), and any custom JSON-LD API options,
such as a document loader. A single <em>selectively revealed document</em>
value, represented as an object, is produced as output.
          </p>

          <ol>
            <li>
Initialize `baseSignature`, `publicKey`, `signatures`, `labelMap`,
`mandatoryIndexes`, `revealDocument` to the values associated with their
property names in the object returned when calling the algorithm in
Section <a href="#createdisclosuredata"></a>, passing the `document`, `proof`,
`selectivePointers`, and any custom JSON-LD API options, such as a document
loader.
            </li>
            <li>
Initialize `newProof` to a shallow copy of `proof`.
            </li>
            <li>
Replace `proofValue` in `newProof` with the result of calling the algorithm
in Section <a href="#serializederivedproofvalue"></a>, passing
`baseSignature`, `publicKey`, `signatures`, `labelMap`, and `mandatoryIndexes`.
            </li>
            <li>
Set the value of the "proof" property in `revealDocument` to `newProof`.
            </li>
            <li>
If `revealDocument` has an `@context` field that includes a <a>verifiable
credential</a> base context and it has a "credentialSubject" property that is a
string, set the "credentialSubject" value to an object with an "id" value that
matches the original string value.
            </li>
            <li>
Return `revealDocument` as the <em>selectively revealed document</em>.
            </li>
          </ol>

        </section>

        <section>
          <h4>Verify Derived Proof (ecdsa-sd-2023)</h4>

          <p>
The following algorithm attempts verification of an `ecdsa-sd-2023` derived
proof. This algorithm is called by a verifier of an ECDSA-SD-protected
<a>verifiable credential</a>. The inputs include a JSON-LD document
(<var>document</var>), an ECDSA-SD disclosure proof (<var>proof</var>), and any
custom JSON-LD API options, such as a document loader. A single boolean
<em>verification result</em> value is produced as output.
          </p>

          <ol class="algorithm">
            <li>
Initialize `baseSignature`, `proofHash`, `publicKey`, `signatures`,
`nonMandatory`, and `mandatoryHash` to the values associated with their property
names in the object returned when calling the algorithm in Section
<a href="#createverifydata"></a>, passing the `document`, `proof`, and any
custom JSON-LD API options, such as a document loader.
            </li>
            <li>
If the length of `signatures` does not match the length of `nonMandatory`, throw
an error indicating that the signature count does not match the non-mandatory
message count.
            </li>
            <li>
Initialize `publicKeyBytes` to the public key bytes expressed in `publicKey`.
Instructions on how to decode the public key value can be found in Section
<a href="#multikey"></a>.
            </li>
            <li>
Initialize `toVerify` to the result of calling the algorithm in Setion
<a href="#serializesigndata"></a>, passing `proofHash`, `publicKey`, and
`mandatoryHash`.
            </li>
            <li>
Initialize `verificationResult` be the result of applying the verification
algorithm of the Elliptic Curve Digital Signature Algorithm (ECDSA) [FIPS-186-5],
with `toVerify` as the data to be verified against the `baseSignature` using
the public key specified by `publicKeyBytes`. If `verificationResult` is
`false`, return `false`.
            </li>
            <li>
For every entry (`index`, `signature`) in `signatures`, verify every signature
for every selectively disclosed (non-mandatory) statement:
              <ol class="algorithm">
                <li>
Initialize `verificationResult` to the result of applying the verification
algorithm Elliptic Curve Digital Signature Algorithm (ECDSA) [FIPS-186-5], with
the UTF-8 representation of the value at `index` of `nonMandatory` as the data
to be verified against `signature` using the public key specified by
`publicKeyBytes`.
                </li>
                <li>
If `verificationResult` is `false`, return `false`.
                </li>
              </ol>
            </li>

            <li>
Return `verificationResult` as <em>verification result</em>.
            </li>
          </ol>

        </section>

      </section>

    </section>
    <section class="informative">
      <h2>Security Considerations</h2>
      <p>
The security (integrity/authenticity) of a verifiable credential
signed by a digital signature algorithm is dependent on a number of factors
including:
      </p>
      <ul>
        <li>
the correct application of the signature algorithm to a verifiable
credential (this specification)
        </li>
        <li>
the choice of signature algorithm (ECDSA) and its parameters (P-256, P-384)
        </li>
        <li>
the correct implementation and usage of the signature algorithm,
particularly with respect to well-known problem areas
        </li>
        <li>
the proper management of the private and public keys used for
signing and verification
        </li>
      </ul>
      <p>
In the following sections, we review these important points and direct
the reader to additional information.
      </p>
      <section class="informative">
        <h3>Choice of ECDSA and Parameters</h3>
        <p>
The ECDSA signature scheme has the <strong>EUF-CMA</strong>
(<em>existential unforgeability under chosen message attacks</em>) security
property. This property guarantees that any efficient adversary who has the
public key <em>pk</em> of the signer and received an arbitrary number of
signatures on messages of its choice (in an adaptive manner) cannot output a
valid signature for a new message (except with negligible probability).
        </p>
        <p>
<strong>SUF-CMA</strong> (<em>strong unforgeability under chosen
message attacks</em>) is a stronger notion than <em>EUF-CMA</em>. It guarantees
that for any efficient adversary who has the public key <em>pk</em> of the
signer and received an arbitrary number of signatures on messages of its
choice, it cannot output a new valid signature pair for a new message
nor a new signature for an old message (except with negligible probability).
 ECDSA signature scheme does <strong>not</strong> have the SUF-CMA property,
 while other schemes such as EdDSA [[FIPS-186-5]] do.
        </p>
        <p>
Per [[NIST-SP-800-57-Part-1]] in the absence of large scale quantum
computers a <em>security strength</em> level of 128 bits requires a key size
of approximately 256 bits while a security strength level of 192 bits requires
a key size of 384 bits. [[NIST-SP-800-186]] recommendations includes curves
P-256 and P-384 at these respective security strength levels.
        </p>
      </section>
      <section class="informative">
        <h3>Implementation Considerations for ECDSA Algorithms</h3>
        <p>
The ECDSA algorithm as detailed in [[FIPS-186-5]] states: &quot;A
new secret random number <em>k</em>, 0 < <em>k</em> < <em>n</em>,
<strong>shall</strong> be generated prior to the generation
of each digital signature for use during the signature generation process.&quot;
The failure to properly generate this <em>k</em> value has lead to some highly
publicized integrity breaches in widely deployed systems. To counter this problem,
a hash-based method of determining the secret number <em>k</em>, called
<em>Deterministic ECDSA</em>, is given in [[FIPS-186-5]] and [[RFC6979]].
Verification of a ECDSA signature is independent of the method of generating
<em>k</em>. Hence it is generally recommended to use <em>Deterministic
ECDSA</em> unless other requirements dictate otherwise.
        </p>
      </section>
      <section class="informative">
        <h3>Key Management</h3>
        <p>
The security of the ECDSA algorithm is dependent on the quality and
protection of its <em>private signing key</em>. Guidance in the management of
cryptographic keys is a large subject and the reader is referred to
[[NIST-SP-800-57-Part-1]] for more extensive recommendations and discussion.
As strongly recommended in both [[FIPS-186-5]] and [[NIST-SP-800-57-Part-1]], an ECDSA
private signing key is not to be used for any other purpose
than ECDSA signatures.
        </p>
        <p>
ECDSA private signing keys and <em>public verification keys</em> are strongly
advised to have limited <em>cryptoperiods</em> [[NIST-SP-800-57-Part-1]], where
a <em>cryptoperiod</em> is &quot;the time span during which a specific key is
authorized for use by legitimate entities or the keys for a given system will
remain in effect.&quot; [[NIST-SP-800-57-Part-1]] gives extensive
guidance on cryptoperiods for different key types under different situations
and generally recommends a 1-3 year cryptoperiod for a private signing key.
        </p>
        <p>
To deal with potential private key compromises, [[NIST-SP-800-57-Part-1]]
gives recommendations for protective measures, harm reduction, and revocation.
Although we have been emphasizing the security of the private signing key,
assurance of public key validity is highly recommended on all public keys
before using them, per [[NIST-SP-800-57-Part-1]].
        </p>
      </section>
      <section>
        <h3>Split Key Formats From Cryptosuites</h3>

        <p class="issue">
Ensuring that cryptographic suites are versioned and tightly scoped to a very
small set of possible key types and signature schemes (ideally one key type and
size and one signature output type) is a design goal for most Data Integrity
cryptographic suites. Historically, this has been done by defining both the
key type and the cryptographic suite that uses the key type in the same
specification. The downside of doing so, however, is that there might be a
proliferation of different key types in multikey that result in different
cryptosuites defining the same key material differently. For example, one
cryptosuite might use compressed Curve P-256 keys while another uses
uncompressed values. If that occurs, it will harm interoperability. It will be
important in the coming months to years to ensure that this does not happen
by fully defining the multikey format in a separate specification so
cryptosuite specifications, such as this one, can refer to the multikey
specification, thus reducing the chances of multikey type proliferation and
improving the chances of maximum interoperability for the multikey format.
        </p>

      </section>
    </section>

    <section>
      <h2>Privacy Considerations</h2>
      <p>
The following section describes privacy considerations that developers
implementing this specification should be aware of in order to avoid violating
privacy assumptions.
      </p>

    </section>

    </section>
    <section class="appendix informative">
      <h2>Test Vectors</h2>
      <p class="note">
All test vectors are produced using <em>Deterministic ECDSA</em>. The
implementation was validated against the test vectors in [[RFC6979]].
      </p>
      <section>
        <h3>Representation: ecdsa-rdfc-2019, with curve P-256</h3>
        <p>
The signer needs to generate a private/public key pair with the private key used
for signing and the public key made available for verification. The
[[MULTIBASE]]/[[MULTICODEC]] representation for the public key, <code>p256-pub</code>,
and the representation for the private key, <code>p256-priv</code>, are shown below.
        </p>
        <pre class="example nohighlight" title="Private and Public keys for Signature"
        data-include="TestVectors/p256KeyPair.json"
        data-include-format="text">
        </pre>

        <p>
Signing begins with a credential without an attached proof, which is converted
to canonical form, which is then hashed, as shown in the following three examples.
        </p>

        <pre class="example nohighlight" title="Credential without Proof" data-include="TestVectors/unsigned.json"
        data-include-format="text"></pre>

        <pre class="example nohighlight" title="Canonical Credential without Proof" data-include="TestVectors/ecdsa-2019-p256/canonDocECDSAP256.txt"
        data-include-format="text"></pre>


        <pre class="example nohighlight" title="Hash of Canonical Credential without Proof (hex)"
        data-include="TestVectors/ecdsa-2019-p256/docHashECDSAP256.txt" data-include-format="text"></pre>

        <p>
The next step is to take the proof options document, convert it to canonical form,
and obtain its hash, as shown in the next three examples.
        </p>

        <pre class="example nohighlight" title="Proof Options Document"
        data-include="TestVectors/ecdsa-2019-p256/proofConfigECDSAP256.json" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Canonical Proof Options Document"
        data-include="TestVectors/ecdsa-2019-p256/proofCanonECDSAP256.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Hash of Canonical Proof Options Document (hex)"
        data-include="TestVectors/ecdsa-2019-p256/proofHashECDSAP256.txt" data-include-format="text"></pre>

        <p>
Finally, we concatenate the hash of the proof options followed by the hash of the credential without proof, use the private key with the combined hash to
compute the ECDSA signature, and then base58-btc encode the signature.
        </p>

        <pre class="example nohighlight" title="Combine hashes of Proof Options and Credential (hex)"
        data-include="TestVectors/ecdsa-2019-p256/combinedHashECDSAP256.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Signature of Combined Hashes (hex)"
        data-include="TestVectors/ecdsa-2019-p256/sigHexECDSAP256.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Signature of Combined Hashes base58-btc"
        data-include="TestVectors/ecdsa-2019-p256/sigBTC58ECDSAP256.txt" data-include-format="text"></pre>

        <p>Assemble the signed credential with the following two steps:</p>
        <ol>
          <li>
Add the <code>proofValue</code> field with the previously computed base58-btc
value to the proof options document.
          </li>
          <li>
Set the <code>proof</code> field of the credential to the augmented proof
option document.
          </li>
        </ol>

        <pre class="example nohighlight" title="Signed Credential"
        data-include="TestVectors/ecdsa-2019-p256/signedECDSAP256.json" data-include-format="text"></pre>
      </section>
      <section>
        <h3>Representation: ecdsa-rdfc-2019, with curve P-384</h3>
        <p>
The signer needs to generate a private/public key pair with the private key used
for signing and the public key made available for verification. The
[[MULTIBASE]]/[[MULTICODEC]] representation for the public key, <code>p384-pub</code>,
and the representation for the private key, <code>p384-priv</code>, are shown below.
        </p>
        <pre class="example nohighlight" title="Private and Public keys for Signature"
        data-include="TestVectors/p384KeyPair.json"
        data-include-format="text">
        </pre>

        <p>
Signing begins with a credential without an attached proof, which is converted
to canonical form, and then hashed, as shown in the following three examples.
        </p>

        <pre class="example nohighlight" title="Credential without Proof" data-include="TestVectors/unsigned.json"
        data-include-format="text"></pre>

        <pre class="example nohighlight" title="Canonical Credential without Proof" data-include="TestVectors/ecdsa-2019-p384/canonDocECDSAP384.txt"
        data-include-format="text"></pre>


        <pre class="example nohighlight" title="Hash of Canonical Credential without Proof (hex)"
        data-include="TestVectors/ecdsa-2019-p384/docHashECDSAP384.txt" data-include-format="text"></pre>

        <p>
The next step is to take the proof options document, convert it to canonical form,
and obtain its hash, as shown in the next three examples.
        </p>

        <pre class="example nohighlight" title="Proof Options Document"
        data-include="TestVectors/ecdsa-2019-p384/proofConfigECDSAP384.json" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Canonical Proof Options Document"
        data-include="TestVectors/ecdsa-2019-p384/proofCanonECDSAP384.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Hash of Canonical Proof Options Document (hex)"
        data-include="TestVectors/ecdsa-2019-p384/proofHashECDSAP384.txt" data-include-format="text"></pre>

        <p>
Finally, we concatenate the hash of the proof options followed by the hash of the credential without proof, use the private key with the combined hash to
compute the ECDSA signature, and then base58-btc encode the signature.
        </p>

        <pre class="example nohighlight" title="Combine hashes of Proof Options and Credential (hex)"
        data-include="TestVectors/ecdsa-2019-p384/combinedHashECDSAP384.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Signature of Combined Hashes (hex)"
        data-include="TestVectors/ecdsa-2019-p384/sigHexECDSAP384.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Signature of Combined Hashes base58-btc"
        data-include="TestVectors/ecdsa-2019-p384/sigBTC58ECDSAP384.txt" data-include-format="text"></pre>

        <p>Assemble the signed credential with the following two steps:</p>
        <ol>
          <li>
Add the <code>proofValue</code> field with the previously computed base58-btc
value to the proof options document.
          </li>
          <li>
Set the <code>proof</code> field of the credential to the augmented proof
option document.
          </li>
        </ol>

        <pre class="example nohighlight" title="Signed Credential"
        data-include="TestVectors/ecdsa-2019-p384/signedECDSAP384.json" data-include-format="text"></pre>
      </section>
      <section>
        <h3>Representation: ecdsa-jcs-2019 with curve P-256</h3>
        <p>
The signer needs to generate a private/public key pair with the private key used
for signing and the public key made available for verification. The
[[MULTIBASE]]/[[MULTICODEC]] representation for the public key, <code>p256-pub</code>,
and the representation for the private key, <code>p256-priv</code>, are shown below.
        </p>
        <pre class="example nohighlight" title="Private and Public keys for Signature"
        data-include="TestVectors/p256KeyPair.json"
        data-include-format="text">
        </pre>

        <p>
Signing begins with a credential without an attached proof, which is converted
to canonical form, which is then hashed, as shown in the following three examples.
        </p>

        <pre class="example nohighlight" title="Credential without Proof" data-include="TestVectors/unsigned.json"
        data-include-format="text"></pre>

        <pre class="example nohighlight" title="Canonical Credential without Proof" data-include="TestVectors/jcs-ecdsa-2019-p256/canonDocJCSECDSAP256.txt"
        data-include-format="text"></pre>


        <pre class="example nohighlight" title="Hash of Canonical Credential without Proof (hex)"
        data-include="TestVectors/jcs-ecdsa-2019-p256/docHashJCSECDSAP256.txt" data-include-format="text"></pre>

        <p>
The next step is to take the proof options document, convert it to canonical form,
and obtain its hash, as shown in the next three examples.
        </p>

        <pre class="example nohighlight" title="Proof Options Document"
        data-include="TestVectors/jcs-ecdsa-2019-p256/proofConfigJCSECDSAP256.json" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Canonical Proof Options Document"
        data-include="TestVectors/jcs-ecdsa-2019-p256/proofCanonJCSECDSAP256.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Hash of Canonical Proof Options Document (hex)"
        data-include="TestVectors/jcs-ecdsa-2019-p256/proofHashJCSECDSAP256.txt" data-include-format="text"></pre>

        <p>
Finally, we concatenate the hash of the proof options followed by the hash of the credential without proof, use the private key with the combined hash to
compute the ECDSA signature, and then base58-btc encode the signature.
        </p>

        <pre class="example nohighlight" title="Combine hashes of Proof Options and Credential (hex)"
        data-include="TestVectors/jcs-ecdsa-2019-p256/combinedHashJCSECDSAP256.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Signature of Combined Hashes (hex)"
        data-include="TestVectors/jcs-ecdsa-2019-p256/sigHexJCSECDSAP256.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Signature of Combined Hashes base58-btc"
        data-include="TestVectors/jcs-ecdsa-2019-p256/sigBTC58JCSECDSAP256.txt" data-include-format="text"></pre>

        <p>Assemble the signed credential with the following two steps:</p>
        <ol>
          <li>
Add the <code>proofValue</code> field with the previously computed base58-btc
value to the proof options document.
          </li>
          <li>
Set the <code>proof</code> field of the credential to the augmented proof
option document.
          </li>
        </ol>

        <pre class="example nohighlight" title="Signed Credential"
        data-include="TestVectors/jcs-ecdsa-2019-p256/signedJCSECDSAP256.json" data-include-format="text"></pre>
      </section>
      <section>
        <h3>Representation: ecdsa-jcs-2019 with curve P-384</h3>
        <p>
The signer needs to generate a private/public key pair with the private key used
for signing and the public key made available for verification. The
[[MULTIBASE]]/[[MULTICODEC]] representation for the public key, <code>p384-pub</code>,
and the representation for the private key, <code>p384-priv</code>, are shown below.
        </p>
        <pre class="example nohighlight" title="Private and Public keys for Signature"
        data-include="TestVectors/p384KeyPair.json"
        data-include-format="text">
        </pre>

        <p>
Signing begins with a credential without an attached proof, which is converted
to canonical form, which is then hashed, as shown in the following three examples.
        </p>

        <pre class="example nohighlight" title="Credential without Proof" data-include="TestVectors/unsigned.json"
        data-include-format="text"></pre>

        <pre class="example nohighlight" title="Canonical Credential without Proof" data-include="TestVectors/jcs-ecdsa-2019-p384/canonDocJCSECDSAP384.txt"
        data-include-format="text"></pre>


        <pre class="example nohighlight" title="Hash of Canonical Credential without Proof (hex)"
        data-include="TestVectors/jcs-ecdsa-2019-p384/docHashJCSECDSAP384.txt" data-include-format="text"></pre>

        <p>
The next step is to take the proof options document, convert it to canonical form,
and obtain its hash, as shown in the next three examples.
        </p>

        <pre class="example nohighlight" title="Proof Options Document"
        data-include="TestVectors/jcs-ecdsa-2019-p384/proofConfigJCSECDSAP384.json" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Canonical Proof Options Document"
        data-include="TestVectors/jcs-ecdsa-2019-p384/proofCanonJCSECDSAP384.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Hash of Canonical Proof Options Document (hex)"
        data-include="TestVectors/jcs-ecdsa-2019-p384/proofHashJCSECDSAP384.txt" data-include-format="text"></pre>

        <p>
Finally, we concatenate the hash of the proof options followed by the hash of the credential without proof, use the private key with the combined hash to
compute the ECDSA signature, and then base58-btc encode the signature.
        </p>

        <pre class="example nohighlight" title="Combine hashes of Proof Options and Credential (hex)"
        data-include="TestVectors/jcs-ecdsa-2019-p384/combinedHashJCSECDSAP384.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Signature of Combined Hashes (hex)"
        data-include="TestVectors/jcs-ecdsa-2019-p384/sigHexJCSECDSAP384.txt" data-include-format="text"></pre>

        <pre class="example nohighlight" title="Signature of Combined Hashes base58-btc"
        data-include="TestVectors/jcs-ecdsa-2019-p384/sigBTC58JCSECDSAP384.txt" data-include-format="text"></pre>

        <p>Assemble the signed credential with the following two steps:</p>
        <ol>
          <li>
Add the <code>proofValue</code> field with the previously computed base58-btc
value to the proof options document.
          </li>
          <li>
Set the <code>proof</code> field of the credential to the augmented proof
option document.
          </li>
        </ol>

        <pre class="example nohighlight" title="Signed Credential"
        data-include="TestVectors/jcs-ecdsa-2019-p384/signedJCSECDSAP384.json" data-include-format="text"></pre>
      </section>
    </section>
  </body>
</html>
